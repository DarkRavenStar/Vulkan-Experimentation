/*
#define GLFW_INCLUDE_VULKAN
#include <GLFW/glfw3.h>

#define GLM_FORCE_RADIANS
#define GLM_FORCE_DEPTH_ZERO_TO_ONE
#include <glm/vec4.hpp>
#include <glm/mat4x4.hpp>

#include <iostream>

int main()
{
	glfwInit();
	glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API);
	GLFWwindow* window = glfwCreateWindow(800, 600, "Vulkan window", nullptr, nullptr);

	uint32_t extensionCount = 0;
	vkEnumerateInstanceExtensionProperties(nullptr, &extensionCount, nullptr);

	std::cout << extensionCount << " extensions supported\n";
	glm::mat4 matrix;
	glm::vec4 vec;
	auto test = matrix * vec;

	while (!glfwWindowShouldClose(window))
	{
		glfwPollEvents();
	}

	glfwDestroyWindow(window);
	glfwTerminate();
	return 0;
}
*/

#define GLFW_INCLUDE_VULKAN
#include <GLFW/glfw3.h>
//Teena - Disabled since GLFW will load it
//#include <vulkan/vulkan.h>

#include <iostream>
#include <stdexcept>
#include <cstdlib>
#include <vector>
#include <string>
#include <cstring>
#include <map>
#include <optional>
#include <set>
#include <cstdint> // Necessary for UINT32_MAX
#include <algorithm> // Necessary for std::clamp
#include <fstream>
#include <array>
#include <thread>
/*
The chrono standard library header exposes functions to do precise timekeeping.
We'll use this to make sure that the geometry rotates 90 degrees per second regardless of frame rate.
*/
#include <chrono>
#include <unordered_map>

/*
The glm/gtc/matrix_transform.hpp header exposes functions that can be
used to generate model transformations like glm::rotate, view transformations
like glm::lookAt and projection transformations like glm::perspective. The
GLM_FORCE_RADIANS definition is necessary to make sure that functions like
glm::rotate use radians as arguments, to avoid any possible confusion.
*/
#define GLM_FORCE_RADIANS
/*
The perspective projection matrix generated by GLM will use the OpenGL depth range
of -1.0 to 1.0 by default. We need to configure it to use the Vulkan range of 0.0
to 1.0 using the GLM_FORCE_DEPTH_ZERO_TO_ONE definition.
*/
#define GLM_FORCE_DEPTH_ZERO_TO_ONE
#include <glm/glm.hpp>
#include <glm/gtc/matrix_transform.hpp>

/*
The hash functions are defined in the gtx folder, which means that
it is technically still an experimental extension to GLM. Therefore
you need to define GLM_ENABLE_EXPERIMENTAL to use it. It means that
the API could change with a new version of GLM in the future, but
in practice the API is very stable.
*/
#define GLM_ENABLE_EXPERIMENTAL
#include <glm/gtx/hash.hpp> //The hash functions for the GLM types

#define STB_IMAGE_IMPLEMENTATION
#include <stb_image.h>

#define TINYOBJLOADER_IMPLEMENTATION
#include <tiny_obj_loader.h>

/*Research Link for more*/
/*
https://en.wikipedia.org/wiki/Z-buffering
https://en.wikipedia.org/wiki/Back-face_culling
https://en.wikipedia.org/wiki/Geometry_instancing
https://en.wikipedia.org/wiki/Stencil_buffer
https://docs.microsoft.com/en-us/windows/uwp/graphics-concepts/depth-and-stencil-buffers
face culling
https://en.wikipedia.org/wiki/Multisample_anti-aliasing
https://en.wikipedia.org/wiki/Shadow_mapping
https://www.reddit.com/r/compsci/comments/40acxe/what_does_sampling_mean_in_graphics/
https://en.wikipedia.org/wiki/Framebuffer
https://learnopengl.com/Advanced-OpenGL/Framebuffers
https://www.youtube.com/watch?v=93bavRgVcwA
https://www.khronos.org/opengl/wiki/Layout_Qualifier_(GLSL)
interleaving vertex attributes - https://anteru.net/blog/2016/storing-vertex-data-to-interleave-or-not-to-interleave/

bindless descriptors

https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator
https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/vkspec.html#commandbuffer-allocation
https://stackoverflow.com/questions/1491394/can-we-execute-a-bat-file-in-post-build-event-command-line-in-visual-studio
https://developer.nvidia.com/vulkan-memory-management

https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/chap7.html#VkPipelineStageFlagBits
https://developer.nvidia.com/gpugems/GPUGems/gpugems_ch11.html
*/


/*
https://vulkan-tutorial.com/en/Drawing_a_triangle/Graphics_pipeline_basics/Introduction

The input assembler collects the raw vertex data from the buffers you specify
and may also use an index buffer to repeat certain elements without having to
duplicate the vertex data itself.

The vertex shader is run for every vertex and generally applies transformations
to turn vertex positions from model space to screen space. It also passes per-vertex
data down the pipeline.

The tessellation shaders allow you to subdivide geometry based on certain rules to
increase the mesh quality. This is often used to make surfaces like brick walls and
staircases look less flat when they are nearby.

The geometry shader is run on every primitive (triangle, line, point) and can discard it
or output more primitives than came in. This is similar to the tessellation shader, but
much more flexible. However, it is not used much in today's applications because the
performance is not that good on most graphics cards except for Intel's integrated GPUs.

The rasterization stage discretizes the primitives into fragments. These are the pixel
elements that they fill on the framebuffer. Any fragments that fall outside the screen
are discarded and the attributes outputted by the vertex shader are interpolated across
the fragments, as shown in the figure. Usually the fragments that are behind other primitive
fragments are also discarded here because of depth testing.

The fragment shader is invoked for every fragment that survives and determines which framebuffer(s)
the fragments are written to and with which color and depth values. It can do this using the
interpolated data from the vertex shader, which can include things like texture coordinates and
normals for lighting.

The color blending stage applies operations to mix different fragments that map to the same pixel
in the framebuffer. Fragments can simply overwrite each other, add up or be mixed based upon
transparency.
*/

const uint32_t WIDTH = 800;
const uint32_t HEIGHT = 600;

const std::string MODEL_PATH = "Models/viking_room.obj";
const std::string TEXTURE_PATH = "Textures/viking_room.png";

const int MAX_FRAMES_IN_FLIGHT = 2;

const std::vector<const char*> g_validationLayers = {
"VK_LAYER_KHRONOS_validation"
};

const std::vector<const char*> g_deviceExtensions = {
	VK_KHR_SWAPCHAIN_EXTENSION_NAME
};

//Teena - NDEBUG: Used to check if the build settings is in Non-Debug mode
#ifdef NDEBUG
const bool enableValidationLayers = false;
#else
const bool enableValidationLayers = true;
#endif

VkResult CreateDebugUtilsMessengerEXT(VkInstance instance,
									  const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo,
									  const VkAllocationCallbacks* pAllocator,
									  VkDebugUtilsMessengerEXT* pDebugMessenger)
{
	auto func = (PFN_vkCreateDebugUtilsMessengerEXT)
		vkGetInstanceProcAddr(instance, "vkCreateDebugUtilsMessengerEXT");
	if (func != nullptr)
	{
		return func(instance, pCreateInfo, pAllocator, pDebugMessenger);
	}
	else
	{
		return VK_ERROR_EXTENSION_NOT_PRESENT;
	}
}

void DestroyDebugUtilsMessengerEXT(VkInstance instance,
								   VkDebugUtilsMessengerEXT debugMessenger,
								   const VkAllocationCallbacks* pAllocator)
{
	auto func = (PFN_vkDestroyDebugUtilsMessengerEXT)
		vkGetInstanceProcAddr(instance,
							  "vkDestroyDebugUtilsMessengerEXT");
	if (func != nullptr)
	{
		func(instance, debugMessenger, pAllocator);
	}
}

static std::vector<char> readFile(const std::string& filename)
{
	/*
	The readFile function will read all of the bytes from the specified
	file and return them in a byte array managed by std::vector. We start
	by opening the file with two flags:

	ate: Start reading at the end of the file
	binary: Read the file as binary file (avoid text transformations)
	*/
	std::ifstream file(filename, std::ios::ate | std::ios::binary);

	if (!file.is_open())
	{
		throw std::runtime_error("failed to open file!");
	}

	/*
	The advantage of starting to read at the end of the file is that we can use the
	read position to determine the size of the file and allocate a buffer:
	*/
	size_t fileSize = (size_t)file.tellg();
	std::vector<char> buffer(fileSize);

	//After that, we can seek back to the beginning of the file and read all of the bytes at once:
	file.seekg(0);
	file.read(buffer.data(), fileSize);

	file.close();

	return buffer;
}

struct QueueFamilyIndices
{
	std::optional<uint32_t> graphicsFamily;
	std::optional<uint32_t> presentFamily;

	bool isComplete()
	{
		return graphicsFamily.has_value() && presentFamily.has_value();
	}
};

struct SwapChainSupportDetails
{
	VkSurfaceCapabilitiesKHR capabilities;
	std::vector<VkSurfaceFormatKHR> formats;
	std::vector<VkPresentModeKHR> presentModes;
};

struct Vertex
{
	glm::vec3 pos;
	glm::vec3 color;
	glm::vec2 texCoord;

	/*
	Binding descriptions
	Tell Vulkan how to pass this data format to the vertex shader once it's
	been uploaded into GPU memory.
	*/
	static VkVertexInputBindingDescription getBindingDescription()
	{
		/*
		A vertex binding describes at which rate to load data from memory throughout
		the vertices. It specifies the number of bytes between data entries and whether
		to move to the next data entry after each vertex or after each instance.

		All of our per-vertex data is packed together in one array, so we're only going
		to have one binding. The binding parameter specifies the index of the binding
		in the array of bindings. The stride parameter specifies the number of bytes
		from one entry to the next, and the inputRate parameter can have one of the following values:

		VK_VERTEX_INPUT_RATE_VERTEX: Move to the next data entry after each vertex
		VK_VERTEX_INPUT_RATE_INSTANCE: Move to the next data entry after each instance

		We're not going to use instanced rendering, so we'll stick to per-vertex data.
		*/
		VkVertexInputBindingDescription bindingDescription{};
		bindingDescription.binding = 0;
		bindingDescription.stride = sizeof(Vertex);
		bindingDescription.inputRate = VK_VERTEX_INPUT_RATE_VERTEX;
		return bindingDescription;
	}

	/*
	Using auto might be a good idea as return type is deducted by the return value
	and it will prevent human error
	*/
	//static std::array<VkVertexInputAttributeDescription, 3> getAttributeDescriptions()
	static auto getAttributeDescriptions()
	{
		/*
		As the function prototype indicates, there are going to be two of these structures.
		An attribute description struct describes how to extract a vertex attribute from a
		chunk of vertex data originating from a binding description. We have two attributes,
		position and color, so we need two attribute description structs.
		*/
		std::array<VkVertexInputAttributeDescription, 3> attributeDescriptions{};

		/*
		The binding parameter tells Vulkan from which binding the per-vertex data comes.
		The location parameter references the location directive of the input in the
		vertex shader. The input in the vertex shader with location 0 is the position,
		which has two 32-bit float components.

		The format parameter describes the type of data for the attribute. A bit confusingly,
		the formats are specified using the same enumeration as color formats. The following
		shader types and formats are commonly used together:

		float: VK_FORMAT_R32_SFLOAT
		vec2: VK_FORMAT_R32G32_SFLOAT
		vec3: VK_FORMAT_R32G32B32_SFLOAT
		vec4: VK_FORMAT_R32G32B32A32_SFLOAT

		As you can see, you should use the format where the amount of color channels matches the
		number of components in the shader data type. It is allowed to use more channels than the
		number of components in the shader, but they will be silently discarded. If the number of
		channels is lower than the number of components, then the BGA components will use default
		values of (0, 0, 1). - need to test this for condition of it happening

		The color type (SFLOAT, UINT, SINT) and bit width should also match the type of the shader
		input. See the following examples:

		ivec2: VK_FORMAT_R32G32_SINT, a 2-component vector of 32-bit signed integers
		uvec4: VK_FORMAT_R32G32B32A32_UINT, a 4-component vector of 32-bit unsigned integers
		double: VK_FORMAT_R64_SFLOAT, a double-precision (64-bit) float

		The format parameter implicitly defines the byte size of attribute data and the offset parameter
		specifies the number of bytes since the start of the per-vertex data to read from. The binding
		is loading one Vertex at a time and the position attribute (pos) is at an offset of 0 bytes from
		the beginning of this struct. This is automatically calculated using the offsetof macro.
		*/
		attributeDescriptions[0].binding = 0;
		attributeDescriptions[0].location = 0;
		attributeDescriptions[0].format = VK_FORMAT_R32G32B32_SFLOAT;
		attributeDescriptions[0].offset = offsetof(Vertex, pos);

		attributeDescriptions[1].binding = 0;
		attributeDescriptions[1].location = 1;
		attributeDescriptions[1].format = VK_FORMAT_R32G32B32_SFLOAT;
		attributeDescriptions[1].offset = offsetof(Vertex, color);

		attributeDescriptions[2].binding = 0;
		attributeDescriptions[2].location = 2;
		attributeDescriptions[2].format = VK_FORMAT_R32G32_SFLOAT;
		attributeDescriptions[2].offset = offsetof(Vertex, texCoord);

		return attributeDescriptions;
	}

	/*
	using a user-defined type like our Vertex struct as key in a hash table requires us
	to implement two functions: equality test and hash calculation. The former is easy
	to implement by overriding the == operator in the Vertex struct:
	*/
	bool operator==(const Vertex& other) const
	{
		return pos == other.pos && color == other.color && texCoord == other.texCoord;
	}
};

namespace std
{
	/*
	A hash function for Vertex is implemented by specifying a template specialization
	for std::hash<T>. Hash functions are a complex topic, but cppreference.com recommends
	the following approach combining the fields of a struct to create a decent quality hash function:
	http://en.cppreference.com/w/cpp/utility/hash
	*/
	template<> struct hash<Vertex>
	{
		size_t operator()(Vertex const& vertex) const
		{
			return ((hash<glm::vec3>()(vertex.pos) ^
				(hash<glm::vec3>()(vertex.color) << 1)) >> 1) ^
					 (hash<glm::vec2>()(vertex.texCoord) << 1);
		}
	};
}

/*
https://vulkan-tutorial.com/en/Uniform_buffers/Descriptor_pool_and_sets#page_Alignment-requirements
Vulkan expects the data in your structure to be aligned in memory in a specific way, for example:

Scalars have to be aligned by N (= 4 bytes given 32 bit floats).
A vec2 must be aligned by 2N (= 8 bytes)
A vec3 or vec4 must be aligned by 4N (= 16 bytes)
A nested structure must be aligned by the base alignment of its members rounded up to a multiple of 16.
A mat4 matrix must have the same alignment as a vec4.
You can find the full list of alignment requirements in the specification.

Our original shader with just three mat4 fields already met the alignment requirements. As each mat4
is 4 x 4 x 4 = 64 bytes in size, model has an offset of 0, view has an offset of 64 and proj has an
offset of 128. All of these are multiples of 16 and that's why it worked fine.

The new structure starts with a vec2 which is only 8 bytes in size and therefore throws off all of the
offsets. Now model has an offset of 8, view an offset of 72 and proj an offset of 136, none of which
are multiples of 16. To fix this problem we can use the alignas specifier introduced in C++11:

https://www.khronos.org/registry/vulkan/specs/1.1-extensions/html/chap14.html#interfaces-resources-layout

V1
struct UniformBufferObject
{
	glm::vec2 foo;
	alignas(16) glm::mat4 model;
	glm::mat4 view;
	glm::mat4 proj;
};

there is a way to not have to think about these alignment requirements most of the time.
We can define GLM_FORCE_DEFAULT_ALIGNED_GENTYPES right before including GLM:

#define GLM_FORCE_RADIANS
#define GLM_FORCE_DEFAULT_ALIGNED_GENTYPES
#include <glm/glm.hpp>

This will force GLM to use a version of vec2 and mat4 that has the alignment requirements already
specified for us. If you add this definition then you can remove the alignas specifier and your
program should still work.

Unfortunately this method can break down if you start using nested structures. Consider the following
definition in the C++ code:

struct Foo {
	glm::vec2 v;
};

struct UniformBufferObject {
	Foo f1;
	Foo f2;
};
And the following shader definition:

struct Foo {
	vec2 v;
};

layout(binding = 0) uniform UniformBufferObject {
	Foo f1;
	Foo f2;
} ubo;

In this case f2 will have an offset of 8 whereas it should have an offset of 16 since it is a
nested structure. In this case you must specify the alignment yourself:

struct UniformBufferObject {
	Foo f1;
	alignas(16) Foo f2;
};

These gotchas are a good reason to always be explicit about alignment. That way you won't be caught
offguard by the strange symptoms of alignment errors.
https://www.geeksforgeeks.org/structure-member-alignment-padding-and-data-packing/
*/
struct UniformBufferObject
{
	alignas(16) glm::mat4 model;
	alignas(16) glm::mat4 view;
	alignas(16) glm::mat4 proj;
};

/*
Now use the Vertex structure to specify an array of vertex data.
We're using exactly the same position and color values as before,
but now they're combined into one array of vertices. This is known
as interleaving vertex attributes.

Google why this is necessary to understand - interleaving vertex attributes
https://anteru.net/blog/2016/storing-vertex-data-to-interleave-or-not-to-interleave/
*/
// const std::vector<Vertex> vertices = {
// 	{{-0.5f, -0.5f, 0.0f}, {1.0f, 0.0f, 0.0f},/*red*/    {1.0f, 0.0f}},
// 	{{0.5f, -0.5f, 0.0f},  {0.0f, 1.0f, 0.0f}, /*green*/ {0.0f, 0.0f}},
// 	{{0.5f, 0.5f, 0.0f},   {0.0f, 0.0f, 1.0f},  /*blue*/ {0.0f, 1.0f}},
// 	{{-0.5f, 0.5f, 0.0f},  {1.0f, 1.0f, 1.0f}, /*white*/ {1.0f, 1.0f}},
// 
// 	{{-0.5f, -0.5f, -0.5f}, {1.0f, 0.0f, 0.0f}, {0.0f, 0.0f}},
// 	{{0.5f, -0.5f, -0.5f}, {0.0f, 1.0f, 0.0f}, {1.0f, 0.0f}},
// 	{{0.5f, 0.5f, -0.5f}, {0.0f, 0.0f, 1.0f}, {1.0f, 1.0f}},
// 	{{-0.5f, 0.5f, -0.5f}, {1.0f, 1.0f, 1.0f}, {0.0f, 1.0f}},
// };

/*
It is possible to use either uint16_t or uint32_t for your index buffer depending on
the number of entries in vertices. We can stick to uint16_t for now because we're using
less than 65535 unique vertices.

Just like the vertex data, the indices need to be uploaded into a VkBuffer for the GPU to
be able to access them.
const std::vector<uint16_t> indices = {
	0, 1, 2, 2, 3, 0,
	4, 5, 6, 6, 7, 4,
};
*/


class HelloTriangleApplication
{
private: // Variables
	GLFWwindow* window = nullptr;

	VkInstance instance;
	VkDebugUtilsMessengerEXT debugMessenger;
	VkSurfaceKHR surface;

	VkPhysicalDevice physicalDevice = VK_NULL_HANDLE;
	VkDevice device;

	//Device queues are implicitly cleaned up when the InDevice is destroyed,
	//so we don't need to do anything in cleanup
	VkQueue graphicsQueue;
	VkQueue presentQueue;

	std::vector<VkImage> swapChainImages;
	std::vector<VkImageView> swapChainImageViews;
	std::vector<VkFramebuffer> swapChainFramebuffers;
	VkSwapchainKHR swapChain;

	VkFormat swapChainImageFormat;
	VkExtent2D swapChainExtent;

	VkRenderPass renderPass;
	VkDescriptorSetLayout descriptorSetLayout;
	VkPipelineLayout pipelineLayout;
	VkPipeline graphicsPipeline;

	VkCommandPool commandPool;

	//Command buffers will be automatically freed when their command pool 
	//is destroyed, so we don't need an explicit cleanup.
	std::vector<VkCommandBuffer> commandBuffers;

	/*
	Theory If reusing the same semaphore for multiple frames, then this error will happen

	validation layer: Validation Error: [ VUID-vkQueueSubmit-pCommandBuffers-00071 ]
	Object 0: handle = 0x222cef95ad8, type = VK_OBJECT_TYPE_DEVICE; | MessageID = 0x2e2f4d65
	| vkQueueSubmit(): pSubmits[0].pCommandBuffers[0] VkCommandBuffer 0x222d5cac7a8[]
	is already in use and is not marked for simultaneous use. The Vulkan spec states:
	If any element of the pCommandBuffers member of any element of pSubmits was not recorded
	with the VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT, it must not be in the pending state
	(https://vulkan.lunarg.com/doc/view/1.2.198.1/windows/1.2-extensions/vkspec.html#VUID-vkQueueSubmit-pCommandBuffers-00071)

	so use an array of it
	*/
	//VkSemaphore imageAvailableSemaphore;
	//VkSemaphore renderFinishedSemaphore;
	std::vector<VkSemaphore> imageAvailableSemaphores;
	std::vector<VkSemaphore> renderFinishedSemaphores;

	std::vector<VkFence> inFlightFences;

	/*
	If MAX_FRAMES_IN_FLIGHT is higher than the number of swap chain images or vkAcquireNextImageKHR
	returns images out-of-order then it's possible that we may start rendering to a swap chain image
	that is already in flight. To avoid this, we need to track for each swap chain image if a frame
	in flight is currently using it. This mapping will refer to frames in flight by their fences so
	we'll immediately have a synchronization object to wait on before a new frame can use that image.
	*/
	std::vector<VkFence> imagesInFlight;
	size_t currentFrame = 0;
	bool framebufferResized = false;

	//Use uint32_t, because there are going to be a lot more vertices than 65535
	std::vector<Vertex> vertices;
	std::vector<uint32_t> indices;
	std::unordered_map<Vertex, uint32_t> uniqueVertices{};

	VkBuffer vertexBuffer;
	VkDeviceMemory vertexBufferMemory;
	VkBuffer indexBuffer;
	VkDeviceMemory indexBufferMemory;
	std::vector<VkBuffer> uniformBuffers;
	std::vector<VkDeviceMemory> uniformBuffersMemory;

	VkDescriptorPool descriptorPool;
	std::vector<VkDescriptorSet> descriptorSets;

	uint32_t mipLevels;
	VkImage textureImage;
	VkDeviceMemory textureImageMemory;
	VkImageView textureImageView;
	VkSampler textureSampler;

	VkImage depthImage;
	VkDeviceMemory depthImageMemory;
	VkImageView depthImageView;

	VkImage colorImage;
	VkDeviceMemory colorImageMemory;
	VkImageView colorImageView;

	VkSampleCountFlagBits msaaSamples = VK_SAMPLE_COUNT_1_BIT;


public: //Functions
	void run()
	{
		initWindow();
		initVulkan();
		mainLoop();
		cleanup();
	}

private: //Functions

	std::vector<const char*> getRequiredExtensions()
	{
		uint32_t glfwExtensionCount = 0;
		const char** glfwExtensions = glfwGetRequiredInstanceExtensions(&glfwExtensionCount);
		std::vector<const char*> extensions(glfwExtensions, glfwExtensions + glfwExtensionCount);
		if (enableValidationLayers)
		{
			extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME);
		}
		return extensions;
	}

	std::vector<VkExtensionProperties> getSupportedExtensionsFromVulkan()
	{
		//Teena - Get list of supported Vulkan extension
		uint32_t extensionPropertiesCount = 0;
		vkEnumerateInstanceExtensionProperties(nullptr, &extensionPropertiesCount, nullptr);

		//Teena - Query Vulkan extension details
		std::vector<VkExtensionProperties> extensionsProperties(extensionPropertiesCount);
		vkEnumerateInstanceExtensionProperties(nullptr, &extensionPropertiesCount, extensionsProperties.data());
		return extensionsProperties;
	}

	QueueFamilyIndices findQueueFamilies(VkPhysicalDevice InDevice)
	{
		//There are different types of queues that originate from different
		//queue families and each family of queues allows only a subset of commands.For
		//example, there could be a queue family that only allows processing of compute
		//commands or one that only allows memory transfer related commands

		QueueFamilyIndices indices;
		// Assign index to queue families that could be found
		//Teena - Retrieve the list of queue families
		uint32_t queueFamilyCount = 0;
		vkGetPhysicalDeviceQueueFamilyProperties(InDevice, &queueFamilyCount, nullptr);
		std::vector<VkQueueFamilyProperties> queueFamilies(queueFamilyCount);
		vkGetPhysicalDeviceQueueFamilyProperties(InDevice, &queueFamilyCount, queueFamilies.data());

		int i = 0;
		for (const auto& queueFamily : queueFamilies)
		{
			//Note that it's very likely that these end up being the same queue family after all,
			//but throughout the program we will treat them as if they were separate queues for a
			//uniform approach. Nevertheless, you could add logic to explicitly prefer a physical
			//InDevice that supports drawing and presentation in the same queue for improved performance.

			//Find queue that can support VK_QUEUE_GRAPHICS_BIT
			if (queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT)
			{
				indices.graphicsFamily = i;
			}

			//Find queue that can support presentation - window surface
			VkBool32 presentSupport = false;
			vkGetPhysicalDeviceSurfaceSupportKHR(InDevice, i, surface, &presentSupport);
			if (presentSupport)
			{
				indices.presentFamily = i;
			}

			if (indices.isComplete())
			{
				break;
			}

			i++;
		}

		std::cout << "Graphics QueueFamilyIndices - " << indices.graphicsFamily.value() << "Present QueueFamilyIndices - " << indices.presentFamily.value() << std::endl;

		return indices;
	}

	//TODO
	void ImplementTransferQueue()
	{
		/*
		Transfer queue

		The buffer copy command requires a queue family that supports transfer operations,
		which is indicated using VK_QUEUE_TRANSFER_BIT. The good news is that any queue
		family with VK_QUEUE_GRAPHICS_BIT or VK_QUEUE_COMPUTE_BIT capabilities already
		implicitly support VK_QUEUE_TRANSFER_BIT operations. The implementation is not
		required to explicitly list it in queueFlags in those cases.

		If you like a challenge, then you can still try to use a different queue family
		specifically for transfer operations. It will require you to make the following
		modifications to your program:

		- Modify QueueFamilyIndices and findQueueFamilies to explicitly look for a queue family
		  with the VK_QUEUE_TRANSFER_BIT bit, but not the VK_QUEUE_GRAPHICS_BIT.

		- Modify createLogicalDevice to request a handle to the transfer queue

		- Create a second command pool for command buffers that are submitted on the transfer queue family

		- Change the sharingMode of resources to be VK_SHARING_MODE_CONCURRENT and specify both the
		  graphics and transfer queue families

		- Submit any transfer commands like vkCmdCopyBuffer to the transfer queue instead
		of the graphics queue. It's a bit of work, but it'll teach you a lot about how resources
		are shared between queue families.
		*/
	}

	//TODO
	void ImplementVulkanMemoryAllocator()
	{
		/*
		It should be noted that in a real world application, you're not supposed to actually call
		vkAllocateMemory for every individual buffer. The maximum number of simultaneous memory
		allocations is limited by the maxMemoryAllocationCount physical device limit, which may be
		as low as 4096 even on high end hardware like an NVIDIA GTX 1080. The right way to allocate
		memory for a large number of objects at the same time is to create a custom allocator that
		splits up a single allocation among many different objects by using the offset parameters
		that we've seen in many functions.

		You can either implement such an allocator yourself, or use the VulkanMemoryAllocator library
		provided by the GPUOpen initiative. However, for this tutorial it's okay to use a separate
		allocation for every resource, because we won't come close to hitting any of these limits for now.

		https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator

		The previous chapter already mentioned that you should allocate multiple resources like buffers
		from a single memory allocation, but in fact you should go a step further. Driver developers
		recommend that you also store multiple buffers, like the vertex and index buffer,
		into a single VkBuffer and use offsets in commands like vkCmdBindVertexBuffers. The advantage is
		that your data is more cache friendly in that case, because it's closer together. It is even
		possible to reuse the same chunk of memory for multiple resources if they are not used during
		the same render operations, provided that their data is refreshed, of course. This is known
		as aliasing and some Vulkan functions have explicit flags to specify that you want to do this.

		https://developer.nvidia.com/vulkan-memory-management
		*/
	}

	//TODO
	void setupCommandBuffer()
	{
		/*
		All of the helper functions that submit commands so far have been set up to execute
		synchronously by waiting for the queue to become idle. For practical applications
		it is recommended to combine these operations in a single command buffer and execute
		them asynchronously for higher throughput, especially the transitions and copy in the
		createTextureImage function. Try to experiment with this by creating a setupCommandBuffer
		that the helper functions record commands into, and add a flushSetupCommands to execute
		the commands that have been recorded so far. It's best to do this after the texture mapping
		works to check if the texture resources are still set up correctly.
		*/
	}

	//TODO
	void generateMipmapsImagesToBeSubmitted()
	{
		/*
		There are two alternatives in this case. You could implement a function that searches common
		texture image formats for one that does support linear blitting, or you could implement the
		mipmap generation in software with a library like stb_image_resize. Each mip level can then
		be loaded into the image in the same way that you loaded the original image.

		It should be noted that it is uncommon in practice to generate the mipmap levels at runtime anyway.
		Usually they are pregenerated and stored in the texture file alongside the base level to improve
		loading speed. Implementing resizing in software and loading multiple levels from a file is left
		as an exercise to the reader.
		*/
	}

	//TODO - Features that can be implement
	void FeaturesThatCanBeImplement()
	{
		/*
		It has taken a lot of work to get to this point, but now you finally have a good base
		for a Vulkan program. The knowledge of the basic principles of Vulkan that you now
		possess should be sufficient to start exploring more of the features, like:

		Push constants
		Instanced rendering
		Dynamic uniforms
		Separate images and sampler descriptors
		Pipeline cache
		Multi-threaded command buffer generation
		Multiple subpasses
		Compute shaders

		The current program can be extended in many ways, like adding Blinn-Phong lighting,
		post-processing effects and shadow mapping. You should be able to learn how these
		effects work from tutorials for other APIs, because despite Vulkan's explicitness,
		many concepts still work the same.
		*/
	}

	SwapChainSupportDetails querySwapChainSupport(VkPhysicalDevice InDevice)
	{
		SwapChainSupportDetails details;

		//function takes the specified VkPhysicalDevice and VkSurfaceKHR window surface into
		//account when determining the supported capabilities
		vkGetPhysicalDeviceSurfaceCapabilitiesKHR(InDevice, surface, &details.capabilities);

		// querying the supported surface formats
		uint32_t formatCount;
		vkGetPhysicalDeviceSurfaceFormatsKHR(InDevice, surface, &formatCount, nullptr);

		if (formatCount != 0)
		{
			details.formats.resize(formatCount);
			vkGetPhysicalDeviceSurfaceFormatsKHR(InDevice, surface, &formatCount, details.formats.data());
		}

		// querying the supported presentation modes
		uint32_t presentModeCount;
		vkGetPhysicalDeviceSurfacePresentModesKHR(InDevice, surface, &presentModeCount, nullptr);

		if (presentModeCount != 0)
		{
			details.presentModes.resize(presentModeCount);
			vkGetPhysicalDeviceSurfacePresentModesKHR(InDevice, surface, &presentModeCount, details.presentModes.data());
		}

		return details;
	}

	void initWindow()
	{
		//Teena - Initialize GLFW
		glfwInit();

		//Teena - Don't initialize opengl context since we are using vulkan
		glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API);

		window = glfwCreateWindow(WIDTH, HEIGHT, "Vulkan", nullptr, nullptr);
		/*
		glfwSetWindowUserPointer basically points a GLFWwindow to a memory location of you choosing
		in this case is this class instance memory location

		You can retrieve the location of the memory for this class instance using glfwGetWindowUserPointer
		https://discourse.glfw.org/t/what-is-a-possible-use-of-glfwgetwindowuserpointer/1294/2
		*/
		glfwSetWindowUserPointer(window, this);
		glfwSetFramebufferSizeCallback(window, framebufferResizeCallback);
	}

	static void framebufferResizeCallback(GLFWwindow* window, int width, int height)
	{
		/*
		glfwSetWindowUserPointer basically points a GLFWwindow to a memory location of you choosing
		in this case is this class instance memory location

		You can retrieve the location of the memory for this class instance using glfwGetWindowUserPointer
		https://discourse.glfw.org/t/what-is-a-possible-use-of-glfwgetwindowuserpointer/1294/2
		*/
		auto app = reinterpret_cast<HelloTriangleApplication*>(glfwGetWindowUserPointer(window));
		app->framebufferResized = true;
	}

	void initVulkan()
	{
		createInstance();
		setupDebugMessenger();
		createSurface();

		pickPhysicalDevice();
		createLogicalDevice();

		createSwapChain();
		createImageViews();
		createRenderPass();

		createDescriptorSetLayout();
		createGraphicsPipeline();

		createColorResources();
		createDepthResources();

		createFramebuffers();

		createCommandPool();

		createTextureImage();
		createTextureImageView();
		createTextureSampler();

		loadModel();

		createVertexBuffer();
		createIndexBuffer();
		createUniformBuffers();

		createDescriptorPool();
		createDescriptorSets();

		createCommandBuffers();
		createSyncObjects();
	}

	void createInstance()
	{
		if (enableValidationLayers && !checkValidationLayerSupport())
		{
			throw std::runtime_error("validation layers requested, but not available!");
		}

		VkApplicationInfo appInfo{};
		appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO;
		appInfo.pApplicationName = "Hello Triangle";
		appInfo.applicationVersion = VK_MAKE_VERSION(1, 0, 0);
		appInfo.pEngineName = "No Engine";
		appInfo.engineVersion = VK_MAKE_VERSION(1, 0, 0);
		appInfo.apiVersion = VK_API_VERSION_1_0;

		//Teena - Get enabled Vulkan global extension from GFLW to create Vulkan instance
		//uint32_t glfwExtensionCount = 0;
		//const char** glfwExtensions = glfwGetRequiredInstanceExtensions(&glfwExtensionCount);

		//Teena - Get required Vulkan global extension from GFLW to create Vulkan instance
		auto requiredExtensions = getRequiredExtensions();
		auto supportedExtensions = getSupportedExtensionsFromVulkan();


		//Teena - Debug info for GLFW require extension vs extension available
		std::cout << "available extensions:\n";
		for (const auto& supportedExt : supportedExtensions)
		{

			std::cout << supportedExt.extensionName << "\n";

			/*
			bool sameExt = false;
			std::cout << supportedExt.extensionName << " - GLFW Required: ";
			for (const auto& requiredExt : requiredExtensions)
			{
				if (strcmp(supportedExt.extensionName, requiredExt) == 0)
				{
					sameExt = true;
				}
			}

			std::cout << (sameExt ? "TRUE" : "FALSE") << '\n';
			*/
		}

		//Teena - create instance - optional can add allocation callback if using custom allocators
		VkInstanceCreateInfo createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
		createInfo.pApplicationInfo = &appInfo;
		createInfo.enabledExtensionCount = static_cast<uint32_t>(requiredExtensions.size());
		createInfo.ppEnabledExtensionNames = requiredExtensions.data();

		VkDebugUtilsMessengerCreateInfoEXT debugCreateInfo;

		if (enableValidationLayers)
		{
			createInfo.enabledLayerCount = static_cast<uint32_t>(g_validationLayers.size());
			createInfo.ppEnabledLayerNames = g_validationLayers.data();
			populateDebugMessengerCreateInfo(debugCreateInfo);
			createInfo.pNext = (VkDebugUtilsMessengerCreateInfoEXT*)&debugCreateInfo;
		}
		else
		{
			createInfo.enabledLayerCount = 0;
			createInfo.pNext = nullptr;
		}

		if (vkCreateInstance(&createInfo, nullptr, &instance) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create instance!");
		}
	}

	void setupDebugMessenger()
	{
		if (!enableValidationLayers) return;

		VkDebugUtilsMessengerCreateInfoEXT createInfo;
		populateDebugMessengerCreateInfo(createInfo);

		if (CreateDebugUtilsMessengerEXT(instance, &createInfo, nullptr, &debugMessenger) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to set up debug messenger!");
		}
	}

	void createSurface()
	{
		//Usually GFLW will take of surface creation for different platform like window, linux, mac os
		//If you want to do it manually, you refer to the code below
		//The process is similar for other platforms like Linux, where vkCreateXcbSurfaceKHR takes an
		//XCB connection and window as creation details with X11.
		//The glfwCreateWindowSurface function performs exactly this operation with a different 
		//implementation for each platform
		/*
		#define VK_USE_PLATFORM_WIN32_KHR
		#define GLFW_INCLUDE_VULKAN
		#include <GLFW/glfw3.h>
		#define GLFW_EXPOSE_NATIVE_WIN32
		#include <GLFW/glfw3native.h>

		VkWin32SurfaceCreateInfoKHR createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR;
		createInfo.hwnd = glfwGetWin32Window(window);
		createInfo.hinstance = GetModuleHandle(nullptr);

		if (vkCreateWin32SurfaceKHR(instance, &createInfo, nullptr, &surface) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create window surface!");
		}
		*/

		if (glfwCreateWindowSurface(instance, window, nullptr, &surface) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create window surface!");
		}

	}

	void pickPhysicalDevice()
	{
		uint32_t deviceCount = 0;
		vkEnumeratePhysicalDevices(instance, &deviceCount, nullptr);

		if (deviceCount == 0)
		{
			throw std::runtime_error("failed to find GPUs with Vulkan support!");
		}

		std::vector<VkPhysicalDevice> physicalDevices(deviceCount);
		vkEnumeratePhysicalDevices(instance, &deviceCount, physicalDevices.data());

		//A bit complicated methods - rank and score graphic physicalDevices
		//Added std::greater<int> as this will allow descending order thus 
		//allowing Nvidia to be chosen first due to its high score
		std::multimap<int, VkPhysicalDevice, std::greater<int>> candidates;
		for (const auto& tempPhyDevice : physicalDevices)
		{
			int score = rateDeviceSuitability(tempPhyDevice);
			candidates.insert(std::make_pair(score, tempPhyDevice));
		}

		//A bit complicated methods - Then check for suitability using queue command - may change in the future
		for (const auto& candidate : candidates)
		{
			//VkPhysicalDeviceProperties devProps{};
			//vkGetPhysicalDeviceProperties(candidate.second, &devProps);
			//std::cout << "Candidates: Physical Device Name: " << devProps.deviceName << " - Score: " << candidate.first << "\n";
			if (isDeviceSuitable(candidate.second))
			{
				physicalDevice = candidate.second;
				//use this function to set the msaaSamples variable during the physical device selection process
				msaaSamples = getMaxUsableSampleCount();
				break;
			}
		}

		VkPhysicalDeviceProperties devProps{};
		vkGetPhysicalDeviceProperties(physicalDevice, &devProps);
		std::cout << "Chosen Physical Device Name: " << devProps.deviceName << "\n";

		/*
		// Check if the best candidate is suitable at all
		if (candidates.rbegin()->first > 0)
		{
			physicalDevice = candidates.rbegin()->second;
		}
		else
		{
			throw std::runtime_error("failed to find a suitable GPU!");
		}
		*/

		if (physicalDevice == VK_NULL_HANDLE)
		{
			throw std::runtime_error("failed to find a suitable GPU!");
		}
	}

	VkSampleCountFlagBits getMaxUsableSampleCount()
	{
		/*
		By default we'll be using only one sample per pixel which is equivalent to no multisampling,
		in which case the final image will remain unchanged. The exact maximum number of samples can
		be extracted from VkPhysicalDeviceProperties associated with our selected physical device.
		We're using a depth buffer, so we have to take into account the sample count for both color
		and depth. The highest sample count that is supported by both (&) will be the maximum we can
		support.
		*/

		VkPhysicalDeviceProperties physicalDeviceProperties;
		vkGetPhysicalDeviceProperties(physicalDevice, &physicalDeviceProperties);

		VkSampleCountFlags counts = physicalDeviceProperties.limits.framebufferColorSampleCounts & physicalDeviceProperties.limits.framebufferDepthSampleCounts;
		if (counts & VK_SAMPLE_COUNT_64_BIT)
		{
			return VK_SAMPLE_COUNT_64_BIT;
		}
		if (counts & VK_SAMPLE_COUNT_32_BIT)
		{
			return VK_SAMPLE_COUNT_32_BIT;
		}
		if (counts & VK_SAMPLE_COUNT_16_BIT)
		{
			return VK_SAMPLE_COUNT_16_BIT;
		}
		if (counts & VK_SAMPLE_COUNT_8_BIT)
		{
			return VK_SAMPLE_COUNT_8_BIT;
		}
		if (counts & VK_SAMPLE_COUNT_4_BIT)
		{
			return VK_SAMPLE_COUNT_4_BIT;
		}
		if (counts & VK_SAMPLE_COUNT_2_BIT)
		{
			return VK_SAMPLE_COUNT_2_BIT;
		}

		return VK_SAMPLE_COUNT_1_BIT;
	}

	void createLogicalDevice()
	{
		//The creation of a logical InDevice involves specifying a bunch of details in structs
		//again, of which the first one will be VkDeviceQueueCreateInfo.This structure
		//describes the number of queues we want for a single queue family.Right now
		//we’re only interested in a queue with graphics capabilities.
		//The currently available drivers will only allow you to create a small number of
		//queues for each queue family and you don’t really need more than one.That’s
		//because you can create all of the command buffers on multiple threads and then
		//submit them all at once on the main thread with a single low - overhead call.
		QueueFamilyIndices indices = findQueueFamilies(physicalDevice);

		std::vector<VkDeviceQueueCreateInfo> queueCreateInfos;
		std::set<uint32_t> uniqueQueueFamilies = { indices.graphicsFamily.value(), indices.presentFamily.value() };

		//Vulkan lets you assign priorities to queues to influence the scheduling of command
		//buffer execution using floating point numbers between 0.0 and 1.0.This
		//is required even if there is only a single queue :
		float queuePriority = 1.0f;
		for (uint32_t queueFamily : uniqueQueueFamilies)
		{
			VkDeviceQueueCreateInfo queueCreateInfo{};
			queueCreateInfo.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;
			queueCreateInfo.queueFamilyIndex = queueFamily;
			queueCreateInfo.queueCount = 1;
			queueCreateInfo.pQueuePriorities = &queuePriority;
			queueCreateInfos.push_back(queueCreateInfo);
		}

		VkPhysicalDeviceFeatures deviceFeatures{};
		/*
		anisotropic filtering is actually an optional device feature so need to request it:
		*/
		deviceFeatures.samplerAnisotropy = VK_TRUE;
		deviceFeatures.sampleRateShading = VK_TRUE; // enable sample shading feature for the device

		VkDeviceCreateInfo createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;
		createInfo.queueCreateInfoCount = queueCreateInfos.size();
		createInfo.pQueueCreateInfos = queueCreateInfos.data();
		createInfo.pEnabledFeatures = &deviceFeatures;
		createInfo.enabledExtensionCount = static_cast<uint32_t>(g_deviceExtensions.size());
		createInfo.ppEnabledExtensionNames = g_deviceExtensions.data();

		if (enableValidationLayers)
		{
			createInfo.enabledLayerCount = static_cast<uint32_t>(g_validationLayers.size());
			createInfo.ppEnabledLayerNames = g_validationLayers.data();
		}
		else
		{
			createInfo.enabledLayerCount = 0;
		}

		if (vkCreateDevice(physicalDevice, &createInfo, nullptr, &device) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create logical device!");
		}

		//We can use the vkGetDeviceQueue function to retrieve queue handles for each queue family.
		//The parameters are the logical InDevice, queue family, queue index and a pointer to the variable
		//to store the queue handle in. Because we're only creating a single queue from this family, 
		//we'll simply use index 0.
		vkGetDeviceQueue(device, indices.graphicsFamily.value(), 0, &graphicsQueue);
		vkGetDeviceQueue(device, indices.presentFamily.value(), 0, &presentQueue);
	}

	void createSwapChain()
	{
		SwapChainSupportDetails swapChainSupport = querySwapChainSupport(physicalDevice);

		VkSurfaceFormatKHR surfaceFormat = chooseSwapSurfaceFormat(swapChainSupport.formats);
		VkPresentModeKHR presentMode = chooseSwapPresentMode(swapChainSupport.presentModes);
		VkExtent2D extent = chooseSwapExtent(swapChainSupport.capabilities);

		//simply sticking to this minimum means that we may sometimes have to wait on the driver
		//to complete internal operations before we can acquire another image to render to.
		//Therefore it is recommended to request at least one more image than the minimum:
		//How many images we would like to have in the swap chain
		uint32_t imageCount = swapChainSupport.capabilities.minImageCount + 1;

		//We should also make sure to not exceed the maximum number of images while doing this,
		//where 0 is a special value that means that there is no maximum :

		if (swapChainSupport.capabilities.maxImageCount > 0 && imageCount > swapChainSupport.capabilities.maxImageCount)
		{
			imageCount = swapChainSupport.capabilities.maxImageCount;
		}

		//The imageArrayLayers specifies the amount of layers each image consists of.
		//This is always 1 unless you are developing a stereoscopic 3D application.
		//The imageUsage bit field specifies what kind of operations we'll use the images
		//in the swap chain for. In this tutorial we're going to render directly to them,
		//which means that they're used as color attachment. It is also possible that you'll
		//render images to a separate image first to perform operations like post - processing.In that case you may use a value like VK_IMAGE_USAGE_TRANSFER_DST_BIT instead and use a memory operation to transfer the rendered image to a swap chain image.
		VkSwapchainCreateInfoKHR createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR;
		createInfo.surface = surface;
		createInfo.minImageCount = imageCount;
		createInfo.imageFormat = surfaceFormat.format;
		createInfo.imageColorSpace = surfaceFormat.colorSpace;
		createInfo.imageExtent = extent;
		createInfo.imageArrayLayers = 1;
		createInfo.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT;

		QueueFamilyIndices indices = findQueueFamilies(physicalDevice);
		uint32_t queueFamilyIndices[] = { indices.graphicsFamily.value(), indices.presentFamily.value() };

		/*
		Next, we need to specify how to handle swap chain images that will be used across multiple queue
		families. That will be the case in our application if the graphics queue family is different from
		the presentation queue. We'll be drawing on the images in the swap chain from the graphics queue
		and then submitting them on the presentation queue. There are two ways to handle images that are
		accessed from multiple queues:

		VK_SHARING_MODE_EXCLUSIVE: An image is owned by one queue family at a time
		and ownership must be explicitly transferred before using it in another queue family.
		This option offers the best performance.
		VK_SHARING_MODE_CONCURRENT: Images can be used across multiple queue families
		without explicit ownership transfers.
		*/

		if (indices.graphicsFamily != indices.presentFamily)
		{
			createInfo.imageSharingMode = VK_SHARING_MODE_CONCURRENT;
			createInfo.queueFamilyIndexCount = 2;
			createInfo.pQueueFamilyIndices = queueFamilyIndices;
		}
		else
		{
			createInfo.imageSharingMode = VK_SHARING_MODE_EXCLUSIVE;
			createInfo.queueFamilyIndexCount = 0; // Optional
			createInfo.pQueueFamilyIndices = nullptr; // Optional
		}


		/*
		We can specify that a certain transform should be applied to images in the swap chain
		if it is supported (supportedTransforms in capabilities), like a 90 degree clockwise
		rotation or horizontal flip. To specify that you do not want any transformation,
		simply specify the current transformation.
		*/
		createInfo.preTransform = swapChainSupport.capabilities.currentTransform;

		/*
		The compositeAlpha field specifies if the alpha channel should be used for blending with other windows
		in the window system. You'll almost always want to simply ignore the alpha channel,
		hence VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR.
		*/
		createInfo.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR;

		/*
		The presentMode member speaks for itself. If the clipped member is set to VK_TRUE
		then that means that we don't care about the color of pixels that are obscured,
		for example because another window is in front of them. Unless you really need to
		be able to read these pixels back and get predictable results, you'll get the best
		performance by enabling clipping.
		*/
		createInfo.presentMode = presentMode;
		createInfo.clipped = VK_TRUE;

		/*
		That leaves one last field, oldSwapChain. With Vulkan it's possible that your swap chain
		becomes invalid or unoptimized while your application is running, for example because the
		window was resized. In that case the swap chain actually needs to be recreated from scratch
		and a reference to the old one must be specified in this field.
		*/
		createInfo.oldSwapchain = VK_NULL_HANDLE;

		if (vkCreateSwapchainKHR(device, &createInfo, nullptr, &swapChain) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create swap chain!");
		}

		/*
		Potential error
		TLDR: Sometimes the if screen is connect to a monitor for laptops,
		the intel integrated GPU will be assigned to it.
		So we have to make to select discrete GPU(Nvidia / AMD) as default to prevent swapchain error

		Fixed this by adding std::greater<int> in pickPhysicalDevice
		std::multimap<int, VkPhysicalDevice, std::greater<int>> candidates;

		this will allow descending order thus allowing Nvidia to be chosen first due to its high score
		https://community.intel.com/t5/Graphics/Vulkan-Access-violation-at-the-vkCreateSwapchainKHR-call-at-64/td-p/1139093
		*/
		vkGetSwapchainImagesKHR(device, swapChain, &imageCount, nullptr);
		swapChainImages.resize(imageCount);
		vkGetSwapchainImagesKHR(device, swapChain, &imageCount, swapChainImages.data());
		swapChainImageFormat = surfaceFormat.format;
		swapChainExtent = extent;
	}

	void createImageViews()
	{
		/*
		To use any VkImage, including those in the swap chain, in the render pipeline we have to
		create a VkImageView object. An image view is quite literally a view into an image.
		It describes how to access the image and which part of the image to access, for example
		if it should be treated as a 2D texture depth texture without any mipmapping levels.
		*/
		swapChainImageViews.resize(swapChainImages.size());

		for (size_t i = 0; i < swapChainImages.size(); i++)
		{
			swapChainImageViews[i] = createImageView(swapChainImages[i], swapChainImageFormat, VK_IMAGE_ASPECT_COLOR_BIT, 1);
		}
	}

	void createRenderPass()
	{
		/*
		Before we can finish creating the pipeline, we need to tell Vulkan
		about the framebuffer attachments that will be used while rendering.
		We need to specify how many color and depth buffers there will be,
		how many samples to use for each of them and how their contents should
		be handled throughout the rendering operations. All of this information
		is wrapped in a render pass object, for which we'll create a new
		createRenderPass function. Call this function from initVulkan before
		createGraphicsPipeline.
		*/

		/*
		The format of the color attachment should match the format of the swap chain images, and
		we're not doing anything with multisampling yet, so we'll stick to 1 sample.

		a single color buffer attachment represented by one of the images from the swap chain.
		*/
		VkAttachmentDescription colorAttachment{};
		colorAttachment.format = swapChainImageFormat;
		//colorAttachment.samples = VK_SAMPLE_COUNT_1_BIT;
		colorAttachment.samples = msaaSamples;
		/*
		The loadOp and storeOp determine what to do with the data in the attachment before
		rendering and after rendering. We have the following choices for loadOp:

		VK_ATTACHMENT_LOAD_OP_LOAD: Preserve the existing contents of the attachment
		VK_ATTACHMENT_LOAD_OP_CLEAR: Clear the values to a constant at the start
		VK_ATTACHMENT_LOAD_OP_DONT_CARE: Existing contents are undefined; we don't care about them

		In our case we're going to use the clear operation to clear the framebuffer to black before
		drawing a new frame. There are only two possibilities for the storeOp:

		VK_ATTACHMENT_STORE_OP_STORE: Rendered contents will be stored in memory and can be read later
		VK_ATTACHMENT_STORE_OP_DONT_CARE: Contents of the framebuffer will be undefined after the
		rendering operation
		*/
		colorAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;
		colorAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE;
		/*
		The loadOp and storeOp apply to color and depth data, and stencilLoadOp / stencilStoreOp
		apply to stencil data. Our application won't do anything with the stencil buffer, so the
		results of loading and storing are irrelevant.
		*/
		colorAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
		colorAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		/*
		Textures and framebuffers in Vulkan are represented by VkImage objects with
		a certain pixel format, however the layout of the pixels in memory can change
		based on what you're trying to do with an image.

		Some of the most common layouts are:

		VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL: Images used as color attachment
		VK_IMAGE_LAYOUT_PRESENT_SRC_KHR: Images to be presented in the swap chain
		VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL: Images to be used as destination
		for a memory copy operation

		The initialLayout specifies which layout the image will have before the render
		pass begins. The finalLayout specifies the layout to automatically transition
		to when the render pass finishes. Using VK_IMAGE_LAYOUT_UNDEFINED for initialLayout
		means that we don't care what previous layout the image was in. The caveat of this
		special value is that the contents of the image are not guaranteed to be preserved,
		but that doesn't matter since we're going to clear it anyway. We want the image to
		be ready for presentation using the swap chain after rendering, which is why we use
		VK_IMAGE_LAYOUT_PRESENT_SRC_KHR as finalLayout.

		You'll notice that we have changed the finalLayout from VK_IMAGE_LAYOUT_PRESENT_SRC_KHR
		to VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL. That's because multisampled images cannot
		be presented directly. We first need to resolve them to a regular image. This requirement
		does not apply to the depth buffer, since it won't be presented at any point. Therefore
		we will have to add only one new attachment for color which is a so-called resolve attachment:
		*/
		colorAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		//colorAttachment.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
		colorAttachment.finalLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;

		//See notes for why we do colorAttachmentResolve in colorAttachment.finalLayout comments
		VkAttachmentDescription colorAttachmentResolve{};
		colorAttachmentResolve.format = swapChainImageFormat;
		colorAttachmentResolve.samples = VK_SAMPLE_COUNT_1_BIT;
		colorAttachmentResolve.loadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
		colorAttachmentResolve.storeOp = VK_ATTACHMENT_STORE_OP_STORE;
		colorAttachmentResolve.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
		colorAttachmentResolve.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		colorAttachmentResolve.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		colorAttachmentResolve.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;

		/*
		The format should be the same as the depth image itself. This time we don't
		care about storing the depth data (storeOp), because it will not be used after
		drawing has finished. This may allow the hardware to perform additional optimizations.
		Just like the color buffer, we don't care about the previous depth contents, so we
		can use VK_IMAGE_LAYOUT_UNDEFINED as initialLayout.
		*/
		VkAttachmentDescription depthAttachment{};
		depthAttachment.format = findDepthFormat();
		//depthAttachment.samples = VK_SAMPLE_COUNT_1_BIT;
		depthAttachment.samples = msaaSamples;
		depthAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;
		depthAttachment.storeOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		depthAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
		depthAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
		depthAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		depthAttachment.finalLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;

		/*
		A single render pass can consist of multiple subpasses. Subpasses are subsequent
		rendering operations that depend on the contents of framebuffers in previous passes,
		for example a sequence of post-processing effects that are applied one after another.
		If you group these rendering operations into one render pass, then Vulkan is able to
		reorder the operations and conserve memory bandwidth for possibly better performance.
		For our very first triangle, however, we'll stick to a single subpass.

		The attachment parameter specifies which attachment to reference by its index in the
		attachment descriptions array. Our array consists of a single VkAttachmentDescription,
		so its index is 0. The layout specifies which layout we would like the attachment to
		have during a subpass that uses this reference. Vulkan will automatically transition
		the attachment to this layout when the subpass is started. We intend to use the attachment
		to function as a color buffer and the VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL layout
		will give us the best performance, as its name implies.
		*/
		VkAttachmentReference colorAttachmentRef{};
		colorAttachmentRef.attachment = 0;
		colorAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;

		VkAttachmentReference depthAttachmentRef{};
		depthAttachmentRef.attachment = 1;
		depthAttachmentRef.layout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;

		/*
		The render pass now has to be instructed to resolve multisampled color image
		into regular attachment. Create a new attachment reference that will point
		to the color buffer which will serve as the resolve target:
		*/
		VkAttachmentReference colorAttachmentResolveRef{};
		colorAttachmentResolveRef.attachment = 2;
		colorAttachmentResolveRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;

		/*
		The index of the attachment in this array is directly referenced from the fragment shader
		with the layout(location = 0) out vec4 outColor directive!

		The following other types of attachments can be referenced by a subpass:

		pInputAttachments: Attachments that are read from a shader
		pResolveAttachments: Attachments used for multisampling color attachments
		pDepthStencilAttachment: Attachment for depth and stencil data
		pPreserveAttachments: Attachments that are not used by this subpass, but for which the
		data must be preserved

		Unlike color attachments, a subpass can only use a single depth (+stencil) attachment.
		It wouldn't really make any sense to do depth tests on multiple buffers.
		*/
		VkSubpassDescription subpass{};
		subpass.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;
		subpass.colorAttachmentCount = 1;
		subpass.pColorAttachments = &colorAttachmentRef;
		subpass.pDepthStencilAttachment = &depthAttachmentRef;
		/*
		Set the pResolveAttachments subpass struct member to point to the newly created attachment
		reference. This is enough to let the render pass define a multisample resolve operation which
		will let us render the image to screen:
		*/
		subpass.pResolveAttachments = &colorAttachmentResolveRef;

		/*
		The first two fields specify the indices of the dependency and the dependent subpass.
		The special value VK_SUBPASS_EXTERNAL refers to the implicit subpass before or after
		the render pass depending ovoid createFramebuffers()n whether it is specified in srcSubpass or dstSubpass.
		The index 0 refers to our subpass, which is the first and only one. The dstSubpass must
		always be higher than srcSubpass to prevent cycles in the dependency graph
		(unless one of the subpasses is VK_SUBPASS_EXTERNAL).

		we need to extend our subpass dependencies to make sure that there is no conflict between
		the transitioning of the depth image and it being cleared as part of its load operation.
		The depth image is first accessed in the early fragment test pipeline stage and because
		we have a load operation that clears, we should specify the access mask for writes.
		*/
		VkSubpassDependency dependency{};
		dependency.srcSubpass = VK_SUBPASS_EXTERNAL;
		dependency.dstSubpass = 0;

		/*
		The next two fields specify the operations to wait on and the stages in which these
		operations occur. We need to wait for the swap chain to finish reading from the image
		before we can access it. This can be accomplished by waiting on the color attachment
		output stage itself.
		*/
		//dependency.srcStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
		dependency.srcStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT | VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
		dependency.srcAccessMask = 0;

		/*
		The operations that should wait on this are in the color attachment stage and involve
		the writing of the color attachment. These settings will prevent the transition from
		happening until it's actually necessary (and allowed): when we want to start writing
		colors to it.
		*/
		//dependency.dstStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
		//dependency.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
		dependency.dstStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT | VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
		dependency.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT | VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;


		std::array<VkAttachmentDescription, 3> attachments = { colorAttachment, depthAttachment, colorAttachmentResolve };
		VkRenderPassCreateInfo renderPassInfo{};
		renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;
		renderPassInfo.attachmentCount = static_cast<uint32_t>(attachments.size());
		renderPassInfo.pAttachments = attachments.data();
		renderPassInfo.subpassCount = 1;
		renderPassInfo.pSubpasses = &subpass;
		renderPassInfo.dependencyCount = 1;
		renderPassInfo.pDependencies = &dependency;

		if (vkCreateRenderPass(device, &renderPassInfo, nullptr, &renderPass) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create render pass!");
		}
	}

	void createDescriptorSetLayout()
	{
		/*
		We're now able to pass arbitrary attributes to the vertex shader for each vertex,
		but what about global variables? We're going to move on to 3D graphics from this
		chapter on and that requires a model-view-projection matrix. We could include it
		as vertex data, but that's a waste of memory and it would require us to update the
		vertex buffer whenever the transformation changes. The transformation could easily
		change every single frame.

		The right way to tackle this in Vulkan is to use resource descriptors. A descriptor
		is a way for shaders to freely access resources like buffers and images. We're going
		to set up a buffer that contains the transformation matrices and have the vertex
		shader access them through a descriptor. Usage of descriptors consists of three parts:

		- Specify a descriptor layout during pipeline creation
		- Allocate a descriptor set from a descriptor pool
		- Bind the descriptor set during rendering

		The descriptor layout specifies the types of resources that are going to be accessed by
		the pipeline, just like a render pass specifies the types of attachments that will be
		accessed. A descriptor set specifies the actual buffer or image resources that will be
		bound to the descriptors, just like a framebuffer specifies the actual image views to
		bind to render pass attachments. The descriptor set is then bound for the drawing commands
		just like the vertex buffers and framebuffer.
		*/

		/*
		The first two fields specify the binding used in the shader and the type of descriptor,
		which is a uniform buffer object. It is possible for the shader variable to represent
		an array of uniform buffer objects, and descriptorCount specifies the number of values
		in the array. This could be used to specify a transformation for each of the bones in
		a skeleton for skeletal animation, for example. Our MVP transformation is in a single
		uniform buffer object, so we're using a descriptorCount of 1.
		*/
		VkDescriptorSetLayoutBinding uboLayoutBinding{};
		uboLayoutBinding.binding = 0;
		uboLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
		uboLayoutBinding.descriptorCount = 1;

		/*
		We also need to specify in which shader stages the descriptor is going to be referenced.
		The stageFlags field can be a combination of VkShaderStageFlagBits values or the value
		VK_SHADER_STAGE_ALL_GRAPHICS. In our case, we're only referencing the descriptor from
		the vertex shader.
		*/
		uboLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT;

		/*
		The pImmutableSamplers field is only relevant for image sampling related descriptors,
		which we'll look at later. You can leave this to its default value.
		*/
		uboLayoutBinding.pImmutableSamplers = nullptr; // Optional

		/*
		new type of descriptor: combined image sampler. This descriptor makes it possible
		for shaders to access an image resource through a sampler object like the one we
		created in the previous chapter.

		We'll start by modifying the descriptor layout, descriptor pool and descriptor set
		to include such a combined image sampler descriptor. After that, we're going to add
		texture coordinates to Vertex and modify the fragment shader to read colors from the
		texture instead of just interpolating the vertex colors.
		*/
		VkDescriptorSetLayoutBinding samplerLayoutBinding{};
		samplerLayoutBinding.binding = 1;
		samplerLayoutBinding.descriptorCount = 1;
		samplerLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
		samplerLayoutBinding.pImmutableSamplers = nullptr;
		/*
		Make sure to set the stageFlags to indicate that we intend to use the combined image
		sampler descriptor in the fragment shader. That's where the color of the fragment is
		going to be determined. It is possible to use texture sampling in the vertex shader,
		for example to dynamically deform a grid of vertices by a heightmap.
		https://en.wikipedia.org/wiki/Heightmap
		*/
		samplerLayoutBinding.stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT;

		//Teena - Disabled since we are doing multiple layout
		//VkDescriptorSetLayoutCreateInfo layoutInfo{};
		//layoutInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO;
		//layoutInfo.bindingCount = 1;
		//layoutInfo.pBindings = &uboLayoutBinding;

		std::array<VkDescriptorSetLayoutBinding, 2> bindings = { uboLayoutBinding, samplerLayoutBinding };
		VkDescriptorSetLayoutCreateInfo layoutInfo{};
		layoutInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO;
		layoutInfo.bindingCount = static_cast<uint32_t>(bindings.size());
		layoutInfo.pBindings = bindings.data();

		if (vkCreateDescriptorSetLayout(device, &layoutInfo, nullptr, &descriptorSetLayout) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create descriptor set layout!");
		}
	}

	void createGraphicsPipeline()
	{
		auto vertShaderCode = readFile("Shader/vert.spv");
		auto fragShaderCode = readFile("Shader/frag.spv");

		//std::cout << "vertShaderCode size: " << vertShaderCode.size() << std::endl;
		//std::cout << "fragShaderCode size: " << fragShaderCode.size() << std::endl;

		VkShaderModule vertShaderModule = createShaderModule(vertShaderCode);
		VkShaderModule fragShaderModule = createShaderModule(fragShaderCode);

		/*
		To actually use the shaders we'll need to assign them to a specific pipeline stage
		through VkPipelineShaderStageCreateInfo structures as part of the actual pipeline
		creation process.
		*/

		/*
		These two members specify the shader module containing the code, and the function to invoke,
		known as the entrypoint. That means that it's possible to combine multiple fragment shaders
		into a single shader module and use different entry points to differentiate between their
		behaviors. In this case we'll stick to the standard main, however.
		vertShaderStageInfo.module = vertShaderModule;
		vertShaderStageInfo.pName = "main";

		There is one more (optional) member, pSpecializationInfo, which we won't be using here,
		but is worth discussing. It allows you to specify values for shader constants.
		You can use a single shader module where its behavior can be configured at pipeline creation
		by specifying different values for the constants used in it. This is more efficient than
		configuring the shader using variables at render time, because the compiler can do optimizations
		like eliminating if statements that depend on these values. If you don't have any constants like
		that, then you can set the member to nullptr, which our struct initialization does automatically.
		*/
		VkPipelineShaderStageCreateInfo vertShaderStageInfo{};
		vertShaderStageInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
		vertShaderStageInfo.stage = VK_SHADER_STAGE_VERTEX_BIT;
		vertShaderStageInfo.module = vertShaderModule;
		vertShaderStageInfo.pName = "main";
		vertShaderStageInfo.pSpecializationInfo = nullptr;

		VkPipelineShaderStageCreateInfo fragShaderStageInfo{};
		fragShaderStageInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
		fragShaderStageInfo.stage = VK_SHADER_STAGE_FRAGMENT_BIT;
		fragShaderStageInfo.module = fragShaderModule;
		fragShaderStageInfo.pName = "main";
		fragShaderStageInfo.pSpecializationInfo = nullptr;

		VkPipelineShaderStageCreateInfo shaderStages[] = { vertShaderStageInfo, fragShaderStageInfo };

		/*
		The VkPipelineVertexInputStateCreateInfo structure describes the format of the vertex data
		that will be passed to the vertex shader. It describes this in roughly two ways:

		Bindings: spacing between data and whether the data is per-vertex or
		per-instance(used for instancing)

		Attribute descriptions: type of the attributes passed to the vertex shader,
		which binding to load them from and at which offset
		*/
		auto bindingDescription = Vertex::getBindingDescription();
		auto attributeDescriptions = Vertex::getAttributeDescriptions();

		VkPipelineVertexInputStateCreateInfo vertexInputInfo{};
		vertexInputInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
		vertexInputInfo.vertexBindingDescriptionCount = 1;
		vertexInputInfo.vertexAttributeDescriptionCount = static_cast<uint32_t>(attributeDescriptions.size());
		vertexInputInfo.pVertexBindingDescriptions = &bindingDescription;
		vertexInputInfo.pVertexAttributeDescriptions = attributeDescriptions.data();

		/*
		The VkPipelineInputAssemblyStateCreateInfo struct describes two things:
		what kind of geometry will be drawn from the vertices and if primitive
		restart should be enabled. The former is specified in the topology member
		and can have values like:

		VK_PRIMITIVE_TOPOLOGY_POINT_LIST: points from vertices
		VK_PRIMITIVE_TOPOLOGY_LINE_LIST: line from every 2 vertices without reuse
		VK_PRIMITIVE_TOPOLOGY_LINE_STRIP: the end vertex of every line is used as
		start vertex for the next line
		VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST: triangle from every 3 vertices without reuse
		VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP: the second and third vertex of every triangle
		are used as first two vertices of the next triangle

		Normally, the vertices are loaded from the vertex buffer by index in sequential order,
		but with an element buffer you can specify the indices to use yourself.
		This allows you to perform optimizations like reusing vertices.
		If you set the primitiveRestartEnable member to VK_TRUE,
		then it's possible to break up lines and triangles in the _STRIP
		topology modes by using a special index of 0xFFFF or 0xFFFFFFFF.
		*/
		VkPipelineInputAssemblyStateCreateInfo inputAssembly{};
		inputAssembly.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;
		inputAssembly.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;
		inputAssembly.primitiveRestartEnable = VK_FALSE;

		/*
		Remember that the size of the swap chain and its images may differ from
		the WIDTH and HEIGHT of the window. The swap chain images will be used
		as framebuffers later on, so we should stick to their size.

		The minDepth and maxDepth values specify the range of depth values to use
		for the framebuffer. These values must be within the [0.0f, 1.0f] range,
		but minDepth may be higher than maxDepth. If you aren't doing anything special,
		then you should stick to the standard values of 0.0f and 1.0f
		*/
		VkViewport viewport{};
		viewport.x = 0.0f;
		viewport.y = 0.0f;
		viewport.width = (float)swapChainExtent.width;
		viewport.height = (float)swapChainExtent.height;
		viewport.minDepth = 0.0f;
		viewport.maxDepth = 1.0f;

		/*
		While viewports define the transformation from the image to the framebuffer,
		scissor rectangles define in which regions pixels will actually be stored.
		Any pixels outside the scissor rectangles will be discarded by the rasterizer.
		They function like a filter rather than a transformation.
		The difference is illustrated below. Note that the left scissor rectangle is
		just one of the many possibilities that would result in that image, as long as
		it's larger than the viewport.

		https://vulkan-tutorial.com/images/viewports_scissors.png
		*/
		VkRect2D scissor{};
		scissor.offset = { 0, 0 };
		scissor.extent = swapChainExtent;

		/*
		Now this viewport and scissor rectangle need to be combined into a viewport
		state using the VkPipelineViewportStateCreateInfo struct. It is possible to
		use multiple viewports and scissor rectangles on some graphics cards, so its
		members reference an array of them. Using multiple requires enabling a GPU
		feature (see logical InDevice creation).
		*/
		VkPipelineViewportStateCreateInfo viewportState{};
		viewportState.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;
		viewportState.viewportCount = 1;
		viewportState.pViewports = &viewport;
		viewportState.scissorCount = 1;
		viewportState.pScissors = &scissor;

		/*
		The rasterizer takes the geometry that is shaped by the vertices from the vertex
		shader and turns it into fragments to be colored by the fragment shader. It also
		performs depth testing, face culling and the scissor test, and it can be configured
		to output fragments that fill entire polygons or just the edges (wireframe rendering).
		All this is configured using the VkPipelineRasterizationStateCreateInfo structure.
		*/

		VkPipelineRasterizationStateCreateInfo rasterizer{};
		rasterizer.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;
		/*
		If depthClampEnable is set to VK_TRUE, then fragments that are beyond the near and
		far planes are clamped to them as opposed to discarding them. This is useful in some
		special cases like shadow maps. Using this requires enabling a GPU feature.
		*/
		rasterizer.depthClampEnable = VK_FALSE;
		/*
		If rasterizerDiscardEnable is set to VK_TRUE, then geometry never passes through
		the rasterizer stage. This basically disables any output to the framebuffer.
		*/
		rasterizer.rasterizerDiscardEnable = VK_FALSE;
		/*
		The polygonMode determines how fragments are generated for geometry.
		The following modes are available:

		VK_POLYGON_MODE_FILL: fill the area of the polygon with fragments
		VK_POLYGON_MODE_LINE: polygon edges are drawn as lines
		VK_POLYGON_MODE_POINT: polygon vertices are drawn as points
		Using any mode other than fill requires enabling a GPU feature.
		*/
		rasterizer.polygonMode = VK_POLYGON_MODE_FILL;
		/*
		The lineWidth member is straightforward, it describes the thickness of lines
		in terms of number of fragments. The maximum line width that is supported
		depends on the hardware and any line thicker than 1.0f requires you to enable
		the wideLines GPU feature.
		*/
		rasterizer.lineWidth = 1.0f;
		/*
		The cullMode variable determines the type of face culling to use.
		You can disable culling, cull the front faces, cull the back faces or both.
		The frontFace variable specifies the vertex order for faces to be considered
		front-facing and can be clockwise or counterclockwise.

		The problem is that because of the Y-flip we did in the projection matrix,
		the vertices are now being drawn in counter-clockwise order instead of
		clockwise order. This causes backface culling to kick in and prevents any
		geometry from being drawn.
		*/
		rasterizer.cullMode = VK_CULL_MODE_BACK_BIT;
		//rasterizer.frontFace = VK_FRONT_FACE_CLOCKWISE;
		rasterizer.frontFace = VK_FRONT_FACE_COUNTER_CLOCKWISE;

		/*
		The rasterizer can alter the depth values by adding a constant value or biasing
		them based on a fragment's slope. This is sometimes used for shadow mapping,
		but we won't be using it. Just set depthBiasEnable to VK_FALSE.
		*/
		rasterizer.depthBiasEnable = VK_FALSE;
		rasterizer.depthBiasConstantFactor = 0.0f; // Optional
		rasterizer.depthBiasClamp = 0.0f; // Optional
		rasterizer.depthBiasSlopeFactor = 0.0f; // Optional

		/*
		The VkPipelineMultisampleStateCreateInfo struct configures multisampling,
		which is one of the ways to perform anti-aliasing. It works by combining
		the fragment shader results of multiple polygons that rasterize to the same
		pixel. This mainly occurs along edges, which is also where the most noticeable
		aliasing artifacts occur. Because it doesn't need to run the fragment shader
		multiple times if only one polygon maps to a pixel, it is significantly less
		expensive than simply rendering to a higher resolution and then downscaling.
		Enabling it requires enabling a GPU feature.
		*/
		VkPipelineMultisampleStateCreateInfo multisampling{};
		multisampling.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;
		//multisampling.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT;
		multisampling.rasterizationSamples = msaaSamples;
		/*
		There are certain limitations of our current MSAA implementation which may impact
		the quality of the output image in more detailed scenes. For example, we're currently
		not solving potential problems caused by shader aliasing, i.e. MSAA only smoothens out
		the edges of geometry but not the interior filling. This may lead to a situation when
		you get a smooth polygon rendered on screen but the applied texture will still look
		aliased if it contains high contrasting colors. One way to approach this problem is
		to enable Sample Shading which will improve the image quality even further, though
		at an additional performance cost:

		Already enable it in createLogicalDevice and createGraphicsPipeline
		*/
		multisampling.sampleShadingEnable = VK_TRUE; // enable sample shading in the pipeline
		multisampling.minSampleShading = 0.2f; // min fraction for sample shading; closer to one is smoother
		//multisampling.sampleShadingEnable = VK_FALSE;
		//multisampling.minSampleShading = 1.0f; // Optional
		multisampling.pSampleMask = nullptr; // Optional
		multisampling.alphaToCoverageEnable = VK_FALSE; // Optional
		multisampling.alphaToOneEnable = VK_FALSE; // Optional

		/*
		The depthTestEnable field specifies if the depth of new fragments should be compared
		to the depth buffer to see if they should be discarded. The depthWriteEnable field
		specifies if the new depth of fragments that pass the depth test should actually be
		written to the depth buffer.
		*/
		VkPipelineDepthStencilStateCreateInfo depthStencil{};
		depthStencil.sType = VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO;
		depthStencil.depthTestEnable = VK_TRUE;
		depthStencil.depthWriteEnable = VK_TRUE;
		/*
		The depthCompareOp field specifies the comparison that is performed to keep or discard
		fragments. We're sticking to the convention of lower depth = closer, so the depth of new
		fragments should be less.
		*/
		depthStencil.depthCompareOp = VK_COMPARE_OP_LESS;
		/*
		The depthBoundsTestEnable, minDepthBounds and maxDepthBounds fields are used for the optional
		depth bound test. Basically, this allows you to only keep fragments that fall within the
		specified depth range. We won't be using this functionality.

		Potential Usage for Occlusion or Frustum Culling maybe??????
		*/
		depthStencil.depthBoundsTestEnable = VK_FALSE;
		depthStencil.minDepthBounds = 0.0f; // Optional
		depthStencil.maxDepthBounds = 1.0f; // Optional
		/*
		The last three fields configure stencil buffer operations, which we also won't be using.
		If you want to use these operations, then you will have to make sure that the format of
		the depth/stencil image contains a stencil component.
		*/
		depthStencil.stencilTestEnable = VK_FALSE;
		depthStencil.front = {}; // Optional
		depthStencil.back = {}; // Optional

		/*
		After a fragment shader has returned a color, it needs to be combined with the
		color that is already in the framebuffer. This transformation is known as color
		blending and there are two ways to do it:

		Mix the old and new value to produce a final color
		Combine the old and new value using a bitwise operation
		There are two types of structs to configure color blending.
		The first struct, VkPipelineColorBlendAttachmentState contains
		the configuration per attached framebuffer and the second struct,
		VkPipelineColorBlendStateCreateInfo contains the global color
		blending settings. In our case we only have one framebuffer:

		If blendEnable is set to VK_FALSE, then the new color from the fragment shader
		is passed through unmodified. Otherwise, the two mixing operations are performed
		to compute a new color. The resulting color is AND'd with the colorWriteMask
		to determine which channels are actually passed through.

		<Pseudo Code Begin>
		if (blendEnable)
		{
			finalColor.rgb = (srcColorBlendFactor * newColor.rgb) < colorBlendOp > (dstColorBlendFactor * oldColor.rgb);
			finalColor.a = (srcAlphaBlendFactor * newColor.a) < alphaBlendOp > (dstAlphaBlendFactor * oldColor.a);
		}
		else
		{
			finalColor = newColor;
		}

		finalColor = finalColor & colorWriteMask;

		The most common way to use color blending is to implement alpha blending, where we
		want the new color to be blended with the old color based on its opacity. The
		finalColor should then be computed as follows:

		finalColor.rgb = newAlpha * newColor + (1 - newAlpha) * oldColor;
		finalColor.a = newAlpha.a;
		<Pseudo Code End>
		*/
		VkPipelineColorBlendAttachmentState colorBlendAttachment{};
		colorBlendAttachment.colorWriteMask = VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT | VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT;
		colorBlendAttachment.blendEnable = VK_FALSE;
		colorBlendAttachment.srcColorBlendFactor = VK_BLEND_FACTOR_ONE; // Optional
		colorBlendAttachment.dstColorBlendFactor = VK_BLEND_FACTOR_ZERO; // Optional
		colorBlendAttachment.colorBlendOp = VK_BLEND_OP_ADD; // Optional
		colorBlendAttachment.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE; // Optional
		colorBlendAttachment.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO; // Optional
		colorBlendAttachment.alphaBlendOp = VK_BLEND_OP_ADD; // Optional

		/*
		//If you need alpha blending - This can be accomplished with the following parameters :
		//You can find all of the possible operations in the VkBlendFactor and VkBlendOp
		enumerations in the specification.

		colorBlendAttachment.blendEnable = VK_TRUE;
		colorBlendAttachment.srcColorBlendFactor = VK_BLEND_FACTOR_SRC_ALPHA;
		colorBlendAttachment.dstColorBlendFactor = VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA;
		colorBlendAttachment.colorBlendOp = VK_BLEND_OP_ADD;
		colorBlendAttachment.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE;
		colorBlendAttachment.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO;
		colorBlendAttachment.alphaBlendOp = VK_BLEND_OP_ADD;
		*/

		/*
		The second structure references the array of structures for all of the framebuffers
		and allows you to set blend constants that you can use as blend factors in the
		aforementioned calculations.

		If you want to use the second method of blending (bitwise combination), then you should
		set logicOpEnable to VK_TRUE. The bitwise operation can then be specified in the logicOp
		field. Note that this will automatically disable the first method, as if you had set
		blendEnable to VK_FALSE for every attached framebuffer! The colorWriteMask will also be
		used in this mode to determine which channels in the framebuffer will actually be affected.
		It is also possible to disable both modes, as we've done here, in which case the fragment
		colors will be written to the framebuffer unmodified.
		*/
		VkPipelineColorBlendStateCreateInfo colorBlending{};
		colorBlending.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;
		colorBlending.logicOpEnable = VK_FALSE;
		colorBlending.logicOp = VK_LOGIC_OP_COPY; // Optional
		colorBlending.attachmentCount = 1;
		colorBlending.pAttachments = &colorBlendAttachment;
		colorBlending.blendConstants[0] = 0.0f; // Optional
		colorBlending.blendConstants[1] = 0.0f; // Optional
		colorBlending.blendConstants[2] = 0.0f; // Optional
		colorBlending.blendConstants[3] = 0.0f; // Optional

		/*
		Dynamic state

		A limited amount of the state that we've specified in the previous structs can actually
		be changed without recreating the pipeline. Examples are the size of the viewport,
		line width and blend constants. If you want to do that, then you'll have to fill in a
		VkPipelineDynamicStateCreateInfo structure like this:

		his will cause the configuration of these values to be ignored and you will be required to
		specify the data at drawing time. This struct can be substituted by a nullptr later on if
		you don't have any dynamic state.

		VkDynamicState dynamicStates[] =
		{
			VK_DYNAMIC_STATE_VIEWPORT,
			VK_DYNAMIC_STATE_LINE_WIDTH
		};

		VkPipelineDynamicStateCreateInfo dynamicState{};
		dynamicState.sType = VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO;
		dynamicState.dynamicStateCount = 2;
		dynamicState.pDynamicStates = &dynamicStates;
		*/

		/*
		You can use uniform values in shaders, which are globals similar to dynamic state variables
		that can be changed at drawing time to alter the behavior of your shaders without having to
		recreate them. They are commonly used to pass the transformation matrix to the vertex shader,
		or to create texture samplers in the fragment shader.

		These uniform values need to be specified during pipeline creation by creating a VkPipelineLayout
		object. we are still required to create an empty pipeline layout.

		The structure also specifies push constants, which are another way of
		passing dynamic values to shaders
		*/
		VkPipelineLayoutCreateInfo pipelineLayoutInfo{};
		pipelineLayoutInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO;
		/*
		specify the descriptor set layout during pipeline creation to tell Vulkan which descriptors
		the shaders will be using

		You may be wondering why it's possible to specify multiple descriptor set layouts here,
		because a single one already includes all of the bindings.

		we'll look into descriptor pools and descriptor sets for the answer.
		*/
		pipelineLayoutInfo.setLayoutCount = 1;
		pipelineLayoutInfo.pSetLayouts = &descriptorSetLayout;

		pipelineLayoutInfo.pushConstantRangeCount = 0; // Optional
		pipelineLayoutInfo.pPushConstantRanges = nullptr; // Optional

		if (vkCreatePipelineLayout(device, &pipelineLayoutInfo, nullptr, &pipelineLayout) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create pipeline layout!");
		}

		/*
		the reference to the render pass and the index of the sub pass where this graphics pipeline will be
		used. It is also possible to use other render passes with this pipeline instead of this specific
		instance, but they have to be compatible with renderPass

		https://www.khronos.org/registry/vulkan/specs/1.0/html/vkspec.html#renderpass-compatibility
		*/
		VkGraphicsPipelineCreateInfo pipelineInfo{};
		pipelineInfo.sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO;
		pipelineInfo.stageCount = 2;
		pipelineInfo.pStages = shaderStages;
		pipelineInfo.pVertexInputState = &vertexInputInfo;
		pipelineInfo.pInputAssemblyState = &inputAssembly;
		pipelineInfo.pViewportState = &viewportState;
		pipelineInfo.pRasterizationState = &rasterizer;
		pipelineInfo.pMultisampleState = &multisampling;
		/*
		A depth stencil state must always be specified if the render pass contains a depth stencil attachment.
		*/
		pipelineInfo.pDepthStencilState = &depthStencil;
		pipelineInfo.pColorBlendState = &colorBlending;
		pipelineInfo.pDynamicState = nullptr; // Optional
		pipelineInfo.layout = pipelineLayout;
		pipelineInfo.renderPass = renderPass;
		pipelineInfo.subpass = 0;

		/*
		There are actually two more parameters: basePipelineHandle and basePipelineIndex.
		Vulkan allows you to create a new graphics pipeline by deriving from an existing
		pipeline. The idea of pipeline derivatives is that it is less expensive to set up
		pipelines when they have much functionality in common with an existing pipeline
		and switching between pipelines from the same parent can also be done quicker.
		You can either specify the handle of an existing pipeline with basePipelineHandle
		or reference another pipeline that is about to be created by index with
		basePipelineIndex. Right now there is only a single pipeline, so we'll simply
		specify a null handle and an invalid index. These values are only used if the
		VK_PIPELINE_CREATE_DERIVATIVE_BIT flag is also specified in the flags field of
		VkGraphicsPipelineCreateInfo.
		*/
		pipelineInfo.basePipelineHandle = VK_NULL_HANDLE; // Optional
		pipelineInfo.basePipelineIndex = -1; // Optional

		/*
		The vkCreateGraphicsPipelines function actually has more parameters than the usual
		object creation functions in Vulkan. It is designed to take multiple VkGraphicsPipelineCreateInfo
		objects and create multiple VkPipeline objects in a single call.

		The second parameter, for which we've passed the VK_NULL_HANDLE argument, references an optional
		VkPipelineCache object. A pipeline cache can be used to store and reuse data relevant to pipeline
		creation across multiple calls to vkCreateGraphicsPipelines and even across program executions
		if the cache is stored to a file. This makes it possible to significantly speed up pipeline
		creation at a later time.
		*/
		if (vkCreateGraphicsPipelines(device, VK_NULL_HANDLE, 1, &pipelineInfo, nullptr, &graphicsPipeline) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create graphics pipeline!");
		}

		vkDestroyShaderModule(device, fragShaderModule, nullptr);
		vkDestroyShaderModule(device, vertShaderModule, nullptr);
	}

	void createFramebuffers()
	{
		swapChainFramebuffers.resize(swapChainImageViews.size());

		for (size_t i = 0; i < swapChainImageViews.size(); i++)
		{
			/*
			The color attachment differs for every swap chain image, but the same depth
			image can be used by all of them because only a single subpass is running at
			the same time due to our semaphores.
			*/
			std::array<VkImageView, 3> attachments = {
				colorImageView,
				depthImageView,
				swapChainImageViews[i],
			};

			VkFramebufferCreateInfo framebufferInfo{};
			framebufferInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;

			/*
			specify with which renderPass the framebuffer needs to be compatible.
			You can only use a framebuffer with the render passes that it is compatible
			with, which roughly means that they use the same number and type of attachments
			*/
			framebufferInfo.renderPass = renderPass;
			framebufferInfo.attachmentCount = static_cast<uint32_t>(attachments.size());
			framebufferInfo.pAttachments = attachments.data();
			framebufferInfo.width = swapChainExtent.width;
			framebufferInfo.height = swapChainExtent.height;
			framebufferInfo.layers = 1;

			if (vkCreateFramebuffer(device, &framebufferInfo, nullptr, &swapChainFramebuffers[i]) != VK_SUCCESS)
			{
				throw std::runtime_error("failed to create framebuffer!");
			}
		}
	}

	void createCommandPool()
	{
		QueueFamilyIndices queueFamilyIndices = findQueueFamilies(physicalDevice);


		/*
		Command buffers are executed by submitting them on one of the InDevice queues,
		like the graphics and presentation queues we retrieved. Each command pool
		can only allocate command buffers that are submitted on a single type of queue.
		We're going to record commands for drawing, which is why we've chosen the graphics queue family.

		There are two possible flags for command pools:

		VK_COMMAND_POOL_CREATE_TRANSIENT_BIT: Hint that command buffers are rerecorded with new commands
		very often (may change memory allocation behavior)

		VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT: Allow command buffers to be rerecorded
		individually, without this flag they all have to be reset together

		We will only record the command buffers at the beginning of the program and then execute them
		many times in the main loop, so we're not going to use either of these flags.
		*/
		VkCommandPoolCreateInfo poolInfo{};
		poolInfo.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;
		poolInfo.queueFamilyIndex = queueFamilyIndices.graphicsFamily.value();
		poolInfo.flags = 0; // Optional

		if (vkCreateCommandPool(device, &poolInfo, nullptr, &commandPool) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create command pool!");
		}
	}

	void createColorResources()
	{
		VkFormat colorFormat = swapChainImageFormat;

		/*
		In MSAA, each pixel is sampled in an offscreen buffer which is then rendered to the screen.
		This new buffer is slightly different from regular images we've been rendering to - they have
		to be able to store more than one sample per pixel. Once a multisampled buffer is created,
		it has to be resolved to the default framebuffer (which stores only a single sample per pixel).
		This is why we have to create an additional render target and modify our current drawing process.
		We only need one render target since only one drawing operation is active at a time, just like
		with the depth buffer.

		We will now create a multisampled color buffer. Add a createColorResources function and
		note that we're using msaaSamples here as a function parameter to createImage. We're also
		using only one mip level, since this is enforced by the Vulkan specification in case of
		images with more than one sample per pixel. Also, this color buffer doesn't need mipmaps
		since it's not going to be used as a texture:
		*/
		createImage(swapChainExtent.width, swapChainExtent.height, 1,
					msaaSamples, colorFormat, VK_IMAGE_TILING_OPTIMAL,
					VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT |
					VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT,
					VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
					colorImage, colorImageMemory);

		colorImageView = createImageView(colorImage, colorFormat, VK_IMAGE_ASPECT_COLOR_BIT, 1);
	}

	void createDepthResources()
	{
		/*
		The usual problem is that the fragments of the lower square are drawn over the fragments
		of the upper square, simply because it comes later in the index array. There are two ways
		to solve this:

		- Sort all of the draw calls by depth from back to front
		- Use depth testing with a depth buffer

		The first approach is commonly used for drawing transparent objects, because order-independent
		transparency is a difficult challenge to solve. However, the problem of ordering fragments by
		depth is much more commonly solved using a depth buffer. A depth buffer is an additional attachment
		that stores the depth for every position, just like the color attachment stores the color of every
		position. Every time the rasterizer produces a fragment, the depth test will check if the new fragment
		is closer than the previous one. If it isn't, then the new fragment is discarded. A fragment that
		passes the depth test writes its own depth to the depth buffer. It is possible to manipulate this
		value from the fragment shader, just like you can manipulate the color output.
		*/

		/*
		A depth attachment is based on an image, just like the color attachment. The difference
		is that the swap chain will not automatically create depth images for us. We only need
		a single depth image, because only one draw operation is running at once. The depth image
		will again require the trifecta of resources: image, memory and image view.
		*/

		/*
		Creating a depth image is fairly straightforward. It should have the same resolution
		as the color attachment, defined by the swap chain extent, an image usage appropriate
		for a depth attachment, optimal tiling and device local memory. The only question is:
		what is the right format for a depth image? The format must contain a depth component,
		indicated by _D??_ in the VK_FORMAT_.

		Unlike the texture image, we don't necessarily need a specific format, because we won't
		be directly accessing the texels from the program. It just needs to have a reasonable
		accuracy, at least 24 bits is common in real-world applications. There are several formats
		that fit this requirement:

		- VK_FORMAT_D32_SFLOAT: 32-bit float for depth
		- VK_FORMAT_D32_SFLOAT_S8_UINT: 32-bit signed float for depth and 8 bit stencil component
		- VK_FORMAT_D24_UNORM_S8_UINT: 24-bit float for depth and 8 bit stencil component

		The stencil component is used for stencil tests, which is an additional test that can be
		combined with depth testing.

		We could simply go for the VK_FORMAT_D32_SFLOAT format, because support for it is extremely
		common (see the hardware database), but it's nice to add some extra flexibility to our
		application where possible.
		*/

		VkFormat depthFormat = findDepthFormat();

		createImage(swapChainExtent.width, swapChainExtent.height, 1,
					msaaSamples, depthFormat,
					VK_IMAGE_TILING_OPTIMAL,
					VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT,
					VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
					depthImage, depthImageMemory);
		depthImageView = createImageView(depthImage, depthFormat, VK_IMAGE_ASPECT_DEPTH_BIT, 1);

		/*
		The undefined layout can be used as initial layout, because there are no existing depth
		image contents that matter

		Running this function will cause error if command pool is not created for command buffer to allocate
		so re-arrange properly if want to use it
		*/
		//transitionImageLayout(depthImage, depthFormat, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL);
	}

	VkFormat findDepthFormat()
	{
		/*
		Make sure to use the VK_FORMAT_FEATURE_ flag instead of VK_IMAGE_USAGE_ in this case.
		All of these candidate formats contain a depth component, but the latter two also contain
		a stencil component. We won't be using that yet, but we do need to take that into account
		when performing layout transitions on images with these formats.
		*/
		return findSupportedFormat(
			{ VK_FORMAT_D32_SFLOAT, VK_FORMAT_D32_SFLOAT_S8_UINT, VK_FORMAT_D24_UNORM_S8_UINT },
			VK_IMAGE_TILING_OPTIMAL,
			VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT
		);
	}

	bool hasStencilComponent(VkFormat format)
	{
		//Add a simple helper function that tells us if the chosen depth format contains a stencil component:
		return format == VK_FORMAT_D32_SFLOAT_S8_UINT || format == VK_FORMAT_D24_UNORM_S8_UINT;
	}

	VkFormat findSupportedFormat(const std::vector<VkFormat>& candidates, VkImageTiling tiling, VkFormatFeatureFlags features)
	{
		/*
		The support of a format depends on the tiling mode and usage, so we must also include these as parameters
		*/
		for (VkFormat format : candidates)
		{
			VkFormatProperties props;
			vkGetPhysicalDeviceFormatProperties(physicalDevice, format, &props);
			/*
			The VkFormatProperties struct contains three fields:

			- linearTilingFeatures: Use cases that are supported with linear tiling
			- optimalTilingFeatures: Use cases that are supported with optimal tiling
			- bufferFeatures: Use cases that are supported for buffers

			Only the first two are relevant here, and the one we check depends on the tiling
			parameter of the function:
			*/
			if (tiling == VK_IMAGE_TILING_LINEAR && (props.linearTilingFeatures & features) == features)
			{
				return format;
			}
			else if (tiling == VK_IMAGE_TILING_OPTIMAL && (props.optimalTilingFeatures & features) == features)
			{
				return format;
			}

			throw std::runtime_error("failed to find supported format!");
		}
	}

	void createTextureImage()
	{
		/*
		The geometry has been colored using per-vertex colors so far, which is a rather
		limited approach. In this part of the tutorial we're going to implement texture
		mapping to make the geometry look more interesting. This will also allow us to
		load and draw basic 3D models.

		Adding a texture to our application will involve the following steps:

		- Create an image object backed by device memory
		- Fill it with pixels from an image file
		- Create an image sampler
		- Add a combined image sampler descriptor to sample colors from the texture

		We've already worked with image objects before, but those were automatically created
		by the swap chain extension. This time we'll have to create one by ourselves. Creating
		an image and filling it with data is similar to vertex buffer creation. We'll start by
		creating a staging resource and filling it with pixel data and then we copy this to the
		final image object that we'll use for rendering. Although it is possible to create a
		staging image for this purpose, Vulkan also allows you to copy pixels from a VkBuffer
		to an image and the API for this is actually faster on some hardware. We'll first create
		this buffer and fill it with pixel values, and then we'll create an image to copy the pixels to.
		Creating an image is not very different from creating buffers. It involves querying the
		memory requirements, allocating device memory and binding it, just like we've seen before.

		However, there is something extra that we'll have to take care of when working with images.
		Images can have different layouts that affect how the pixels are organized in memory.
		Due to the way graphics hardware works, simply storing the pixels row by row may not
		lead to the best performance, for example. When performing any operation on images,
		you must make sure that they have the layout that is optimal for use in that operation.
		We've actually already seen some of these layouts when we specified the render pass:

		VK_IMAGE_LAYOUT_PRESENT_SRC_KHR: Optimal for presentation
		VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL: Optimal as attachment for writing colors from the fragment shader
		VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL: Optimal as source in a transfer operation, like vkCmdCopyImageToBuffer
		VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL: Optimal as destination in a transfer operation, like vkCmdCopyBufferToImage
		VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL: Optimal for sampling from a shader

		One of the most common ways to transition the layout of an image is a pipeline barrier.
		Pipeline barriers are primarily used for synchronizing access to resources, like making
		sure that an image was written to before it is read, but they can also be used to
		transition layouts. In this chapter we'll see how pipeline barriers are used for
		this purpose. Barriers can additionally be used to transfer queue family ownership
		when using VK_SHARING_MODE_EXCLUSIVE.

		we'll load an image and upload it into a Vulkan image object. We're going to use command buffers,
		so it should be called after createCommandPool.
		*/

		/*
		The stbi_load function takes the file path and number of channels to load as arguments.
		The STBI_rgb_alpha value forces the image to be loaded with an alpha channel, even if it
		doesn't have one, which is nice for consistency with other textures in the future. The
		middle three parameters are outputs for the width, height and actual number of channels
		in the image. The pointer that is returned is the first element in an array of pixel values.
		The pixels are laid out row by row with 4 bytes per pixel in the case of STBI_rgb_alpha for
		a total of texWidth * texHeight * 4 values.
		*/
		int texWidth, texHeight, texChannels;
		//stbi_uc* pixels = stbi_load("Textures/texture.jpg", &texWidth, &texHeight, &texChannels, STBI_rgb_alpha);
		stbi_uc* pixels = stbi_load(TEXTURE_PATH.c_str(), &texWidth, &texHeight, &texChannels, STBI_rgb_alpha);
		VkDeviceSize imageSize = texWidth * texHeight * 4;

		if (!pixels)
		{
			throw std::runtime_error("failed to load texture image!");
		}

		/*
		Mipmaps are precalculated, downscaled versions of an image. Each new image is half
		the width and height of the previous one. Mipmaps are used as a form of Level of Detail
		or LOD. Objects that are far away from the camera will sample their textures from the
		smaller mip images. Using smaller images increases the rendering speed and avoids artifacts
		such as Moiré patterns. An example of what mipmaps look like:
		https://en.wikipedia.org/wiki/Moir%C3%A9_pattern
		https://vulkan-tutorial.com/images/mipmaps_example.jpg

		In Vulkan, each of the mip images is stored in different mip levels of a VkImage. Mip level 0 is
		the original image, and the mip levels after level 0 are commonly referred to as the mip chain.

		The number of mip levels is specified when the VkImage is created. Up until now, we have always
		set this value to one. We need to calculate the number of mip levels from the dimensions of the image.

		This calculates the number of levels in the mip chain. The max function selects the largest dimension.
		The log2 function calculates how many times that dimension can be divided by 2. The floor function
		handles cases where the largest dimension is not a power of 2. 1 is added so that the original
		image has a mip level.
		*/
		//https://www.calculator.net/log-calculator.html?xv=1024&base=2&yv=&x=43&y=25
		mipLevels = static_cast<uint32_t>(std::floor(std::log2(std::max(texWidth, texHeight)))) + 1;

		//create a buffer in host visible memory so that we can use vkMapMemory and copy the pixels to it.
		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;

		/*
		The buffer should be in host visible memory so that we can map it and it should be usable as
		a transfer source so that we can copy it to an image later on:
		*/
		createBuffer(imageSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
					 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
					 VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
					 stagingBuffer, stagingBufferMemory);

		/*
		We can then directly copy the pixel values that we got from the image loading
		library to the buffer:
		*/
		void* data;
		vkMapMemory(device, stagingBufferMemory, 0, imageSize, 0, &data);
		memcpy(data, pixels, static_cast<size_t>(imageSize));
		vkUnmapMemory(device, stagingBufferMemory);

		stbi_image_free(pixels);

		/*
		Our texture image now has multiple mip levels, but the staging buffer can only be used
		to fill mip level 0. The other levels are still undefined. To fill these levels we need
		to generate the data from the single level that we have. We will use the vkCmdBlitImage
		command. This command performs copying, scaling, and filtering operations. We will call
		this multiple times to blit data to each level of our texture image.

		vkCmdBlitImage is considered a transfer operation, so we must inform Vulkan that we intend
		to use the texture image as both the source and destination of a transfer. Add
		VK_IMAGE_USAGE_TRANSFER_SRC_BIT to the texture image's usage flags in createTextureImage:
		*/
		createImage(texWidth, texHeight, mipLevels,
					VK_SAMPLE_COUNT_1_BIT,
					VK_FORMAT_R8G8B8A8_SRGB,
					VK_IMAGE_TILING_OPTIMAL,
					VK_IMAGE_USAGE_TRANSFER_DST_BIT |
					VK_IMAGE_USAGE_TRANSFER_SRC_BIT |
					VK_IMAGE_USAGE_SAMPLED_BIT,
					VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
					textureImage, textureImageMemory);

		/*
		The image was created with the VK_IMAGE_LAYOUT_UNDEFINED layout, so that one should
		be specified as old layout when transitioning textureImage. Remember that we can do
		this because we don't care about its contents before performing the copy operation.
		*/
		transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_SRGB,
							  VK_IMAGE_LAYOUT_UNDEFINED,
							  VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL);

		copyBufferToImage(stagingBuffer, textureImage, static_cast<uint32_t>(texWidth), static_cast<uint32_t>(texHeight));

		/*
		To be able to start sampling from the texture image in the shader, we need one last
		transition to prepare it for shader access:

		Like other image operations, vkCmdBlitImage depends on the layout of the image
		it operates on. We could transition the entire image to VK_IMAGE_LAYOUT_GENERAL,
		but this will most likely be slow. For optimal performance, the source image should
		be in VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL and the destination image should be in
		VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL. Vulkan allows us to transition each mip level
		of an image independently. Each blit will only deal with two mip levels at a time,
		so we can transition each level into the optimal layout between blits commands.

		transitionImageLayout only performs layout transitions on the entire image, so we'll
		need to write a few more pipeline barrier commands

		This will leave each level of the texture image in VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL.
		Each level will be transitioned to VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL after the
		blit command reading from it is finished.
		*/
		/*
		if (mipLevels == 0)
		{
			transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_SRGB,
								  VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
								  VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
		}
		else
		{
			generateMipmaps(textureImage, VK_FORMAT_R8G8B8A8_SRGB, texWidth, texHeight, mipLevels);
		}
		*/
		generateMipmaps(textureImage, VK_FORMAT_R8G8B8A8_SRGB, texWidth, texHeight, mipLevels);

		vkDestroyBuffer(device, stagingBuffer, nullptr);
		vkFreeMemory(device, stagingBufferMemory, nullptr);
	}

	void generateMipmaps(VkImage image, VkFormat imageFormat, int32_t texWidth, int32_t texHeight, uint32_t mipLevels)
	{
		// Check if image format supports linear blitting
		VkFormatProperties formatProperties;
		vkGetPhysicalDeviceFormatProperties(physicalDevice, imageFormat, &formatProperties);

		/*
		The VkFormatProperties struct has three fields named linearTilingFeatures,
		optimalTilingFeatures and bufferFeatures that each describe how the format
		can be used depending on the way it is used. We create a texture image with
		the optimal tiling format, so we need to check optimalTilingFeatures. Support
		for the linear filtering feature can be checked with the
		VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT:
		*/
		if (!(formatProperties.optimalTilingFeatures & VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT))
		{
			throw std::runtime_error("texture image format does not support linear blitting!");
		}

		VkCommandBuffer commandBuffer = beginSingleTimeCommands();

		/*
		We're going to make several transitions, so we'll reuse this VkImageMemoryBarrier.
		The fields set above will remain the same for all barriers. subresourceRange.miplevel,
		oldLayout, newLayout, srcAccessMask, and dstAccessMask will be changed for each transition.
		*/
		VkImageMemoryBarrier barrier{};
		barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
		barrier.image = image;
		barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		barrier.subresourceRange.baseArrayLayer = 0;
		barrier.subresourceRange.layerCount = 1;
		barrier.subresourceRange.levelCount = 1;

		int32_t mipWidth = texWidth;
		int32_t mipHeight = texHeight;

		for (uint32_t i = 1; i < mipLevels; i++)
		{
			/*
			First, we transition level i - 1 to VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL.
			This transition will wait for level i - 1 to be filled, either from the
			previous blit command, or from vkCmdCopyBufferToImage. The current blit
			command will wait on this transition.
			*/
			barrier.subresourceRange.baseMipLevel = i - 1;
			barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
			barrier.newLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
			barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			barrier.dstAccessMask = VK_ACCESS_TRANSFER_READ_BIT;

			vkCmdPipelineBarrier(commandBuffer,
								 VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_TRANSFER_BIT, 0,
								 0, nullptr,
								 0, nullptr,
								 1, &barrier);

			/*
			specify the regions that will be used in the blit operation. The source mip level is
			i - 1 and the destination mip level is i. The two elements of the srcOffsets array
			determine the 3D region that data will be blitted from. dstOffsets determines the
			region that data will be blitted to. The X and Y dimensions of the dstOffsets[1] are
			divided by two since each mip level is half the size of the previous level. The
			Z dimension of srcOffsets[1] and dstOffsets[1] must be 1, since a 2D image has a depth of 1.
			*/
			VkImageBlit blit{};
			blit.srcOffsets[0] = { 0, 0, 0 };
			blit.srcOffsets[1] = { mipWidth, mipHeight, 1 };
			blit.srcSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
			blit.srcSubresource.mipLevel = i - 1;
			blit.srcSubresource.baseArrayLayer = 0;
			blit.srcSubresource.layerCount = 1;
			blit.dstOffsets[0] = { 0, 0, 0 };
			blit.dstOffsets[1] = { mipWidth > 1 ? mipWidth / 2 : 1, mipHeight > 1 ? mipHeight / 2 : 1, 1 };
			blit.dstSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
			blit.dstSubresource.mipLevel = i;
			blit.dstSubresource.baseArrayLayer = 0;
			blit.dstSubresource.layerCount = 1;

			/*
			Now, we record the blit command. Note that textureImage is used for both the srcImage and
			dstImage parameter. This is because we're blitting between different levels of the same
			image. The source mip level was just transitioned to VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL
			and the destination level is still in VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL from
			createTextureImage.

			Beware if you are using a dedicated transfer queue (as suggested in Vertex buffers):
			vkCmdBlitImage must be submitted to a queue with graphics capability.

			The last parameter allows us to specify a VkFilter to use in the blit. We have the same
			filtering options here that we had when making the VkSampler. We use the VK_FILTER_LINEAR
			to enable interpolation.
			*/
			vkCmdBlitImage(commandBuffer,
						   image, VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
						   image, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
						   1, &blit,
						   VK_FILTER_LINEAR);

			barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
			barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
			barrier.srcAccessMask = VK_ACCESS_TRANSFER_READ_BIT;
			barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

			vkCmdPipelineBarrier(commandBuffer,
								 VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0,
								 0, nullptr,
								 0, nullptr,
								 1, &barrier);
			/*
			At the end of the loop, we divide the current mip dimensions by two. We check each dimension
			before the division to ensure that dimension never becomes 0. This handles cases where the
			image is not square, since one of the mip dimensions would reach 1 before the other dimension.
			When this happens, that dimension should remain 1 for all remaining levels.
			*/
			if (mipWidth > 1) mipWidth /= 2;
			if (mipHeight > 1) mipHeight /= 2;
		}

		/*
		Before we end the command buffer, we insert one more pipeline barrier.
		This barrier transitions the last mip level from VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL
		to VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL. This wasn't handled by the loop, since the
		last mip level is never blitted from.
		*/
		barrier.subresourceRange.baseMipLevel = mipLevels - 1;
		barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
		barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
		barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
		barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

		vkCmdPipelineBarrier(commandBuffer,
							 VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0,
							 0, nullptr,
							 0, nullptr,
							 1, &barrier);

		endSingleTimeCommands(commandBuffer);
	}

	void createTextureImageView()
	{
		/*
		Same as createImageViews. The only two changes you have to make are the format and the image:
		*/
		textureImageView = createImageView(textureImage, VK_FORMAT_R8G8B8A8_SRGB, VK_IMAGE_ASPECT_COLOR_BIT, mipLevels);
	}

	void createTextureSampler()
	{
		/*
		It is possible for shaders to read texels directly from images, but that is not very
		common when they are used as textures. Textures are usually accessed through samplers,
		which will apply filtering and transformations to compute the final color that is retrieved.

		These filters are helpful to deal with problems like oversampling. Consider a texture that is
		mapped to geometry with more fragments than texels. If you simply took the closest texel for
		the texture coordinate in each fragment, then you would get a result like the first image:

		If you combined the 4 closest texels through linear interpolation, then you would get a smoother
		result like the one on the right(bilinear filtering) vs no filtering. Of course your application
		may have art style requirements that fit the left style more (think Minecraft), but the right is
		preferred in conventional graphics applications. A sampler object automatically applies this
		filtering for you when reading a color from the texture.

		https://vulkan-tutorial.com/images/texture_filtering.png

		Undersampling is the opposite problem, where you have more texels than fragments. This will lead to
		artifacts when sampling high frequency patterns like a checkerboard texture at a sharp angle:

		https://vulkan-tutorial.com/images/anisotropic_filtering.png

		As shown in the left image, the texture turns into a blurry mess in the distance. The solution to
		this is anisotropic filtering, which can also be applied automatically by a sampler.

		Aside from these filters, a sampler can also take care of transformations. It determines what happens
		when you try to read texels outside the image through its addressing mode. The image below displays
		some of the possibilities

		https://vulkan-tutorial.com/images/texture_addressing.png

		While the VkImage holds the mipmap data, VkSampler controls how that data is read while rendering.
		Vulkan allows us to specify minLod, maxLod, mipLodBias, and mipmapMode
		("Lod" means "Level of Detail"). When a texture is sampled, the sampler selects a mip level
		according to the following pseudocode:

		lod = getLodLevelFromScreenSize(); //smaller when the object is close, may be negative
		lod = clamp(lod + mipLodBias, minLod, maxLod);

		//clamped to the number of mip levels in the texture
		level = clamp(floor(lod), 0, texture.mipLevels - 1);

		if (mipmapMode == VK_SAMPLER_MIPMAP_MODE_NEAREST) {
			color = sample(level);
		} else {
			color = blend(sample(level), sample(level + 1));
		}
		If samplerInfo.mipmapMode is VK_SAMPLER_MIPMAP_MODE_NEAREST,
		lod selects the mip level to sample from. If the mipmap mode is VK_SAMPLER_MIPMAP_MODE_LINEAR,
		lod is used to select two mip levels to be sampled. Those levels are sampled and the results
		are linearly blended.

		The sample operation is also affected by lod:

		if (lod <= 0) {
			color = readTexture(uv, magFilter);
		} else {
			color = readTexture(uv, minFilter);
		}

		If the object is close to the camera, magFilter is used as the filter. If the object is further
		from the camera, minFilter is used. Normally, lod is non-negative, and is only 0 when close the
		camera. mipLodBias lets us force Vulkan to use lower lod and level than it would normally use.

		we need to choose values for our textureSampler. We've already set the minFilter and magFilter
		to use VK_FILTER_LINEAR. We just need to choose values for minLod, maxLod, mipLodBias, and mipmapMode.

		To allow the full range of mip levels to be used, we set minLod to 0.0f, and maxLod to the number of
		mip levels. We have no reason to change the lod value , so we set mipLodBias to 0.0f.
		*/

		/*
		The magFilter and minFilter fields specify how to interpolate texels that are magnified or minified.
		Magnification concerns the oversampling problem describes above, and minification concerns
		undersampling. The choices are VK_FILTER_NEAREST and VK_FILTER_LINEAR, corresponding to the modes
		demonstrated in the images above.
		*/
		VkSamplerCreateInfo samplerInfo{};
		samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
		samplerInfo.magFilter = VK_FILTER_LINEAR;
		samplerInfo.minFilter = VK_FILTER_LINEAR;

		/*
		The addressing mode can be specified per axis using the addressMode fields. The available values are
		listed below. Most of these are demonstrated in the image above. Note that the axes are called
		U, V and W instead of X, Y and Z. This is a convention for texture space coordinates.

		- VK_SAMPLER_ADDRESS_MODE_REPEAT: Repeat the texture when going beyond the image dimensions.
		- VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT: Like repeat, but inverts the coordinates to mirror
		the image when going beyond the dimensions.
		- VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE: Take the color of the edge closest to the coordinate
		beyond the image dimensions.
		- VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE: Like clamp to edge, but instead uses the edge
		opposite to the closest edge.
		- VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER: Return a solid color when sampling beyond the dimensions
		of the image.

		It doesn't really matter which addressing mode we use here, because we're not going to sample outside
		of the image in this tutorial. However, the repeat mode is probably the most common mode, because it
		can be used to tile textures like floors and walls.
		*/
		samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT;

		/*
		These two fields specify if anisotropic filtering should be used. There is no reason not to use this
		unless performance is a concern. The maxAnisotropy field limits the amount of texel samples that can
		be used to calculate the final color. A lower value results in better performance, but lower quality
		results. To figure out which value we can use, we need to retrieve the properties of the physical
		device like so:

		You can either query the properties at the beginning of your program and pass them around to the
		functions that need them, or query them in the function itself.
		*/
		VkPhysicalDeviceProperties properties{};
		vkGetPhysicalDeviceProperties(physicalDevice, &properties);
		/*
		If you look at the documentation for the VkPhysicalDeviceProperties structure, you'll see that it
		contains a VkPhysicalDeviceLimits member named limits. This struct in turn has a member called
		maxSamplerAnisotropy and this is the maximum value we can specify for maxAnisotropy. If we want
		to go for maximum quality, we can simply use that value directly:
		*/
		samplerInfo.anisotropyEnable = VK_TRUE;
		samplerInfo.maxAnisotropy = properties.limits.maxSamplerAnisotropy;

		/*
		The borderColor field specifies which color is returned when sampling beyond the image with clamp
		to border addressing mode. It is possible to return black, white or transparent in either float
		or int formats. You cannot specify an arbitrary color.
		*/
		samplerInfo.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK;

		/*
		The unnormalizedCoordinates field specifies which coordinate system you want to use to address
		texels in an image. If this field is VK_TRUE, then you can simply use coordinates within the
		[0, texWidth) and [0, texHeight) range. If it is VK_FALSE, then the texels are addressed using
		the [0, 1) range on all axes. Real-world applications almost always use normalized coordinates,
		because then it's possible to use textures of varying resolutions with the exact same coordinates.
		*/
		samplerInfo.unnormalizedCoordinates = VK_FALSE;

		/*
		If a comparison function is enabled, then texels will first be compared to a value, and the result
		of that comparison is used in filtering operations. This is mainly used for percentage-closer
		filtering on shadow maps.
		https://developer.nvidia.com/gpugems/GPUGems/gpugems_ch11.html
		*/
		samplerInfo.compareEnable = VK_FALSE;
		samplerInfo.compareOp = VK_COMPARE_OP_ALWAYS;

		/*
		All of these fields apply to mipmapping and basically it's another type of filter that can be applied.
		*/
		samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;
		samplerInfo.minLod = 0.0f; // Optional
		samplerInfo.maxLod = static_cast<float>(mipLevels);
		samplerInfo.mipLodBias = 0.0f; // Optional

		/*
		Note the sampler does not reference a VkImage anywhere. The sampler is a distinct object that provides
		an interface to extract colors from a texture. It can be applied to any image you want, whether it is
		1D, 2D or 3D. This is different from many older APIs, which combined texture images and filtering
		into a single state.
		*/
		if (vkCreateSampler(device, &samplerInfo, nullptr, &textureSampler) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create texture sampler!");
		}
	}

	VkImageView createImageView(VkImage image, VkFormat format, VkImageAspectFlags aspectFlags, uint32_t mipLevels)
	{
		VkImageViewCreateInfo viewInfo{};
		viewInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO;
		viewInfo.image = image;

		/*
		The viewType and format fields specify how the image data should be interpreted.
		The viewType parameter allows you to treat images as 1D textures, 2D textures,
		3D textures and cube maps.
		*/
		viewInfo.viewType = VK_IMAGE_VIEW_TYPE_2D;
		viewInfo.format = format;

		/*
		The components field allows you to swizzle the color channels around.
		For example, you can map all of the channels to the red channel for a
		monochrome texture. You can also map constant values of 0 and 1 to a channel.
		In our case we'll stick to the default mapping.

		left out the explicit viewInfo.components initialization, because
		VK_COMPONENT_SWIZZLE_IDENTITY is defined as 0 anyway.
		*/
		//viewInfo.components.r = VK_COMPONENT_SWIZZLE_IDENTITY;
		//viewInfo.components.g = VK_COMPONENT_SWIZZLE_IDENTITY;
		//viewInfo.components.b = VK_COMPONENT_SWIZZLE_IDENTITY;
		//viewInfo.components.a = VK_COMPONENT_SWIZZLE_IDENTITY;

		/*
		The subresourceRange field describes what the image's purpose is and which part
		of the image should be accessed. Our images will be used as color targets without
		any mipmapping levels or multiple layers.
		*/
		//viewInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		viewInfo.subresourceRange.aspectMask = aspectFlags;
		viewInfo.subresourceRange.baseMipLevel = 0;
		viewInfo.subresourceRange.levelCount = mipLevels;
		viewInfo.subresourceRange.baseArrayLayer = 0;
		viewInfo.subresourceRange.layerCount = 1;

		/*
		If you were working on a stereographic 3D application, then you would create a swap
		chain with multiple layers. You could then create multiple image views for each image
		representing the views for the left and right eyes by accessing different layers.
		*/
		VkImageView imageView;
		if (vkCreateImageView(device, &viewInfo, nullptr, &imageView) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create texture image view!");
		}

		return imageView;
	}

	void createImage(uint32_t width, uint32_t height, uint32_t mipLevels,
					 VkSampleCountFlagBits numSamples, VkFormat format,
					 VkImageTiling tiling, VkImageUsageFlags usage,
					 VkMemoryPropertyFlags properties, VkImage& image,
					 VkDeviceMemory& imageMemory)
	{
		/*
		Although we could set up the shader to access the pixel values in the buffer, it's better
		to use image objects in Vulkan for this purpose. Image objects will make it easier and
		faster to retrieve colors by allowing us to use 2D coordinates, for one. Pixels within
		an image object are known as texels and we'll use that name from this point on.
		*/
		VkImageCreateInfo imageInfo{};
		imageInfo.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO;
		/*
		The image type, specified in the imageType field, tells Vulkan with what kind of
		coordinate system the texels in the image are going to be addressed. It is possible
		to create 1D, 2D and 3D images. One dimensional images can be used to store an
		array of data or gradient, two dimensional images are mainly used for textures,
		and three dimensional images can be used to store voxel volumes, for example.
		*/
		imageInfo.imageType = VK_IMAGE_TYPE_2D;
		/*
		The extent field specifies the dimensions of the image, basically how many texels
		there are on each axis. That's why depth must be 1 instead of 0. Our texture will
		not be an array and we won't be using mipmapping for now.
		*/
		imageInfo.extent.width = width;
		imageInfo.extent.height = height;
		imageInfo.extent.depth = 1;
		imageInfo.mipLevels = mipLevels;
		imageInfo.arrayLayers = 1;
		/*
		Vulkan supports many possible image formats, but we should use the same format for
		the texels as the pixels in the buffer, otherwise the copy operation will fail.
		*/
		//imageInfo.format = VK_FORMAT_R8G8B8A8_SRGB;
		imageInfo.format = format;

		/*
		The tiling field can have one of two values:

		VK_IMAGE_TILING_LINEAR: Texels are laid out in row-major order like our pixels array
		VK_IMAGE_TILING_OPTIMAL: Texels are laid out in an implementation defined order for
		optimal access

		Unlike the layout of an image, the tiling mode cannot be changed at a later time.
		If you want to be able to directly access texels in the memory of the image, then
		you must use VK_IMAGE_TILING_LINEAR. We will be using a staging buffer instead of
		a staging image, so this won't be necessary. We will be using VK_IMAGE_TILING_OPTIMAL
		for efficient access from the shader.
		*/
		//imageInfo.tiling = VK_IMAGE_TILING_OPTIMAL;
		imageInfo.tiling = tiling;

		/*
		There are only two possible values for the initialLayout of an image:

		VK_IMAGE_LAYOUT_UNDEFINED: Not usable by the GPU and the very first transition
		will discard the texels.

		VK_IMAGE_LAYOUT_PREINITIALIZED: Not usable by the GPU, but the first transition
		will preserve the texels.

		There are few situations where it is necessary for the texels to be preserved
		during the first transition. One example, however, would be if you wanted to use
		an image as a staging image in combination with the VK_IMAGE_TILING_LINEAR layout.
		In that case, you'd want to upload the texel data to it and then transition the
		image to be a transfer source without losing the data. In our case, however, we're
		first going to transition the image to be a transfer destination and then copy texel
		data to it from a buffer object, so we don't need this property and can safely use
		VK_IMAGE_LAYOUT_UNDEFINED.
		*/
		imageInfo.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		/*
		The usage field has the same semantics as the one during buffer creation.
		The image is going to be used as destination for the buffer copy, so it should
		be set up as a transfer destination. We also want to be able to access the image
		from the shader to color our mesh, so the usage should include VK_IMAGE_USAGE_SAMPLED_BIT.
		*/
		//imageInfo.usage = VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_SAMPLED_BIT;
		imageInfo.usage = usage;
		/*
		The samples flag is related to multisampling. This is only relevant for images that will be
		used as attachments, so stick to one sample. There are some optional flags for images that
		are related to sparse images. Sparse images are images where only certain regions are actually
		backed by memory. If you were using a 3D texture for a voxel terrain, for example, then you
		could use this to avoid allocating memory to store large volumes of "air" values. We won't be
		using it in this tutorial, so leave it to its default value of 0.
		*/
		//imageInfo.samples = VK_SAMPLE_COUNT_1_BIT;
		imageInfo.samples = numSamples;
		imageInfo.flags = 0; // Optional
		imageInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE;

		/*
		The image is created using vkCreateImage, which doesn't have any particularly noteworthy
		parameters. It is possible that the VK_FORMAT_R8G8B8A8_SRGB format is not supported by
		the graphics hardware. You should have a list of acceptable alternatives and go with the
		best one that is supported. However, support for this particular format is so widespread
		that we'll skip this step. Using different formats would also require annoying conversions.
		We will get back to this in the depth buffer chapter, where we'll implement such a system.
		*/
		if (vkCreateImage(device, &imageInfo, nullptr, &image) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create image!");
		}

		VkMemoryRequirements memRequirements;
		vkGetImageMemoryRequirements(device, image, &memRequirements);

		VkMemoryAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
		allocInfo.allocationSize = memRequirements.size;
		allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, properties);

		if (vkAllocateMemory(device, &allocInfo, nullptr, &imageMemory) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to allocate image memory!");
		}

		vkBindImageMemory(device, image, imageMemory, 0);
	}

	void createBuffer(VkDeviceSize size, VkBufferUsageFlags usage, VkMemoryPropertyFlags properties, VkBuffer& buffer, VkDeviceMemory& bufferMemory)
	{
		/*
		Buffers in Vulkan are regions of memory used for storing arbitrary data
		that can be read by the graphics card. They can be used to store vertex data,
		which we'll do in this chapter, but they can also be used for many other
		purposes that we'll explore in future chapters. Unlike the Vulkan objects
		we've been dealing with so far, buffers do not automatically allocate memory
		for themselves. The work from the previous chapters has shown that the Vulkan
		API puts the programmer in control of almost everything and memory management
		is one of those things.
		*/
		VkBufferCreateInfo bufferInfo{};
		bufferInfo.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;

		/*
		The first field of the struct is size, which specifies the size of the buffer in bytes.
		Calculating the byte size of the vertex data is straightforward with sizeof.
		*/
		//bufferInfo.size = sizeof(vertices[0]) * vertices.size();
		bufferInfo.size = size;

		/*
		The second field is usage, which indicates for which purposes the data in the buffer is
		going to be used. It is possible to specify multiple purposes using a bitwise or.
		Our use case will be a vertex buffer
		*/
		//bufferInfo.usage = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT;
		bufferInfo.usage = usage;

		/*
		Just like the images in the swap chain, buffers can also be owned by a specific queue
		family or be shared between multiple at the same time. The buffer will only be used from
		the graphics queue, so we can stick to exclusive access.
		*/
		bufferInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE;

		/*
		The flags parameter is used to configure sparse buffer memory, which is not relevant right now.
		We'll leave it at the default value of 0.
		*/
		//bufferInfo.flags = 0

		if (vkCreateBuffer(device, &bufferInfo, nullptr, &buffer) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create vertex buffer!");
		}

		/*
		The buffer has been created, but it doesn't actually have any memory assigned to it yet.
		The first step of allocating memory for the buffer is to query its memory requirements
		using the aptly named vkGetBufferMemoryRequirements function.

		The VkMemoryRequirements struct has three fields:

		size: The size of the required amount of memory in bytes, may differ from bufferInfo.size.

		alignment: The offset in bytes where the buffer begins in the allocated region of memory,
		depends on bufferInfo.usage and bufferInfo.flags.

		memoryTypeBits: Bit field of the memory types that are suitable for the buffer.

		Graphics cards can offer different types of memory to allocate from. Each type of memory
		varies in terms of allowed operations and performance characteristics. We need to combine
		the requirements of the buffer and our own application requirements to find the right type
		of memory to use

		https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkMemoryPropertyFlagBits.html
		*/
		VkMemoryRequirements memRequirements;
		vkGetBufferMemoryRequirements(device, buffer, &memRequirements);

		VkMemoryAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
		allocInfo.allocationSize = memRequirements.size;
		//allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT);
		allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, properties);

		if (vkAllocateMemory(device, &allocInfo, nullptr, &bufferMemory) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to allocate vertex buffer memory!");
		}

		/*
		The first three parameters are self-explanatory and the fourth parameter is the offset
		within the region of memory. Since this memory is allocated specifically for this the
		vertex buffer, the offset is simply 0. If the offset is non-zero, then it is required
		to be divisible by memRequirements.alignment.
		*/
		vkBindBufferMemory(device, buffer, bufferMemory, 0);

	}

	void createCommandBuffers()
	{
		commandBuffers.resize(swapChainFramebuffers.size());

		/*
		The level parameter specifies if the allocated command buffers
		are primary or secondary command buffers.

		VK_COMMAND_BUFFER_LEVEL_PRIMARY: Can be submitted to a queue for execution,
		but cannot be called from other command buffers.

		VK_COMMAND_BUFFER_LEVEL_SECONDARY: Cannot be submitted directly, but can be
		called from primary command buffers.

		We won't make use of the secondary command buffer functionality here, but you
		can imagine that it's helpful to reuse common operations from primary command buffers.
		*/
		VkCommandBufferAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
		allocInfo.commandPool = commandPool;
		allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
		allocInfo.commandBufferCount = (uint32_t)commandBuffers.size();

		if (vkAllocateCommandBuffers(device, &allocInfo, commandBuffers.data()) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to allocate command buffers!");
		}

		/*
		The flags parameter specifies how we're going to use the command buffer.
		The following values are available:

		VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT: The command buffer will be rerecorded
		right after executing it once.

		VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT: This is a secondary command buffer
		that will be entirely within a single render pass.

		VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT: The command buffer can be resubmitted
		while it is also already pending execution.

		None of these flags are applicable for us right now.

		The pInheritanceInfo parameter is only relevant for secondary command buffers.
		It specifies which state to inherit from the calling primary command buffers.

		If the command buffer was already recorded once, then a call to vkBeginCommandBuffer
		will implicitly reset it. It's not possible to append commands to a buffer at a later time.

		Probably can append it if vkBeginCommandBuffer is not called straight away

		*/
		for (size_t i = 0; i < commandBuffers.size(); i++)
		{
			VkCommandBufferBeginInfo beginInfo{};
			beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
			beginInfo.flags = 0; // Optional
			beginInfo.pInheritanceInfo = nullptr; // Optional

			if (vkBeginCommandBuffer(commandBuffers[i], &beginInfo) != VK_SUCCESS)
			{
				throw std::runtime_error("failed to begin recording command buffer!");
			}

			/*
			Drawing starts by beginning the render pass with vkCmdBeginRenderPass.
			The render pass is configured using some parameters in a VkRenderPassBeginInfo struct.
			*/
			VkRenderPassBeginInfo renderPassInfo{};
			renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;
			/*
			The first parameters are the render pass itself and the attachments to bind.
			We created a framebuffer for each swap chain image that specifies it as color attachment.
			*/
			renderPassInfo.renderPass = renderPass;
			renderPassInfo.framebuffer = swapChainFramebuffers[i];

			/*
			The next two parameters define the size of the render area.
			The render area defines where shader loads and stores will take place.
			The pixels outside this region will have undefined values.
			It should match the size of the attachments for best performance.
			*/
			renderPassInfo.renderArea.offset = { 0, 0 };
			renderPassInfo.renderArea.extent = swapChainExtent;

			/*
			The last two parameters define the clear values to use for VK_ATTACHMENT_LOAD_OP_CLEAR,
			which we used as load operation for the color attachment. I've defined the clear color
			to simply be black with 100% opacity.
			*/
			//VkClearValue clearColor = { {{0.0f, 0.0f, 0.0f, 1.0f}} };
			//renderPassInfo.clearValueCount = 1;
			//renderPassInfo.pClearValues = &clearColor;
			/*
			Because we now have multiple attachments with VK_ATTACHMENT_LOAD_OP_CLEAR, we also need
			to specify multiple clear values

			The range of depths in the depth buffer is 0.0 to 1.0 in Vulkan, where 1.0 lies at the
			far view plane and 0.0 at the near view plane. The initial value at each point in the
			depth buffer should be the furthest possible depth, which is 1.0.

			Note that the order of clearValues should be identical to the order of your attachments.
			*/
			std::array<VkClearValue, 2> clearValues{};
			clearValues[0].color = { {0.0f, 0.0f, 0.0f, 1.0f} };
			clearValues[1].depthStencil = { 1.0f, 0 };
			renderPassInfo.clearValueCount = static_cast<uint32_t>(clearValues.size());
			renderPassInfo.pClearValues = clearValues.data();

			/*
			The render pass can now begin. All of the functions that record commands can be recognized
			by their vkCmd prefix. They all return void, so there will be no error handling until we've
			finished recording.

			The first parameter for every command is always the command buffer to record the command to.
			The second parameter specifies the details of the render pass we've just provided.
			The final parameter controls how the drawing commands within the render pass will be provided.
			It can have one of two values:

			VK_SUBPASS_CONTENTS_INLINE: The render pass commands will be embedded in the primary command buffer itself and no secondary command buffers will be executed.
			VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS: The render pass commands will be executed from secondary command buffers.

			We will not be using secondary command buffers, so we'll go with the first option.
			*/
			vkCmdBeginRenderPass(commandBuffers[i], &renderPassInfo, VK_SUBPASS_CONTENTS_INLINE);

			/*
			The second parameter specifies if the pipeline object is a graphics or compute pipeline.
			We've now told Vulkan which operations to execute in the graphics pipeline and which
			attachment to use in the fragment shader, so all that remains is telling it to draw the
			triangle:
			*/
			vkCmdBindPipeline(commandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, graphicsPipeline);

			/*
			The vkCmdBindVertexBuffers function is used to bind vertex buffers to bindings.
			The first two parameters, besides the command buffer, specify the offset and number
			of bindings we're going to specify vertex buffers for. The last two parameters specify
			the array of vertex buffers to bind and the byte offsets to start reading vertex data from.
			You should also change the call to vkCmdDraw to pass the number of vertices in the buffer as opposed to the hardcoded number 3.
			*/
			VkBuffer vertexBuffers[] = { vertexBuffer };
			VkDeviceSize offsets[] = { 0 };
			vkCmdBindVertexBuffers(commandBuffers[i], 0, 1, vertexBuffers, offsets);

			/*
			We first need to bind the index buffer, just like we did for the vertex buffer.
			The difference is that you can only have a single index buffer. It's unfortunately
			not possible to use different indices for each vertex attribute, so we do still
			have to completely duplicate vertex data even if just one attribute varies.

			An index buffer is bound with vkCmdBindIndexBuffer which has the index buffer,
			a byte offset into it, and the type of index data as parameters. As mentioned before,
			the possible types are VK_INDEX_TYPE_UINT16 and VK_INDEX_TYPE_UINT32.

			//Use VK_INDEX_TYPE_UINT32, because there are going to be a lot more vertices than 65535
			*/
			vkCmdBindIndexBuffer(commandBuffers[i], indexBuffer, 0, VK_INDEX_TYPE_UINT32);

			/*
			vkCmdDraw

			vertexCount: Even though we don't have a vertex buffer, we technically still have
			3 vertices to draw.

			instanceCount: Used for instanced rendering, use 1 if you're not doing that.

			firstVertex: Used as an offset into the vertex buffer, defines the lowest value of
			gl_VertexIndex.

			firstInstance: Used as an offset for instanced rendering, defines the lowest value of
			gl_InstanceIndex.
			*/
			//vkCmdDraw(commandBuffers[i], static_cast<uint32_t>(vertices.size()), 1, 0, 0);

			/*
			Unlike vertex and index buffers, descriptor sets are not unique to graphics pipelines.
			Therefore we need to specify if we want to bind descriptor sets to the graphics or
			compute pipeline. The next parameter is the layout that the descriptors are based on.
			The next three parameters specify the index of the first descriptor set, the number of
			sets to bind, and the array of sets to bind. We'll get back to this in a moment. The
			last two parameters specify an array of offsets that are used for dynamic descriptors.
			*/
			vkCmdBindDescriptorSets(commandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, pipelineLayout, 0, 1, &descriptorSets[i], 0, nullptr);

			/*
			change the drawing command to tell Vulkan to use the index buffer.
			Remove the vkCmdDraw line and replace it with vkCmdDrawIndexed:

			A call to this function is very similar to vkCmdDraw. The first two
			parameters specify the number of indices and the number of instances.
			We're not using instancing, so just specify 1 instance. The number of
			indices represents the number of vertices that will be passed to the
			vertex buffer. The next parameter specifies an offset into the index buffer,
			using a value of 1 would cause the graphics card to start reading at the
			second index. The second to last parameter specifies an offset to add to
			the indices in the index buffer. The final parameter specifies an offset
			for instancing, which we're not using.
			*/
			vkCmdDrawIndexed(commandBuffers[i], static_cast<uint32_t>(indices.size()), 1, 0, 0, 0);

			vkCmdEndRenderPass(commandBuffers[i]);

			if (vkEndCommandBuffer(commandBuffers[i]) != VK_SUCCESS)
			{
				throw std::runtime_error("failed to record command buffer!");
			}
		}
	}

	void createSyncObjects()
	{
		imageAvailableSemaphores.resize(MAX_FRAMES_IN_FLIGHT);
		renderFinishedSemaphores.resize(MAX_FRAMES_IN_FLIGHT);
		inFlightFences.resize(MAX_FRAMES_IN_FLIGHT);

		//Initially not a single frame is using an image so we explicitly initialize it to no fence.
		imagesInFlight.resize(swapChainImages.size(), VK_NULL_HANDLE);

		VkSemaphoreCreateInfo semaphoreInfo{};
		semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;

		/*
		Need to initialize fence as signaled so that the draw function won't
		get fenced before drawing the frames first - VK_FENCE_CREATE_SIGNALED_BIT
		*/
		VkFenceCreateInfo fenceInfo{};
		fenceInfo.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;
		fenceInfo.flags = VK_FENCE_CREATE_SIGNALED_BIT;

		for (size_t i = 0; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			if (vkCreateSemaphore(device, &semaphoreInfo, nullptr, &imageAvailableSemaphores[i]) != VK_SUCCESS ||
				vkCreateSemaphore(device, &semaphoreInfo, nullptr, &renderFinishedSemaphores[i]) != VK_SUCCESS ||
				vkCreateFence(device, &fenceInfo, nullptr, &inFlightFences[i]) != VK_SUCCESS)
			{
				throw std::runtime_error("failed to create synchronization objects for a frame!");
			}
		}
	}

	void loadModel()
	{
		/*
		 populate the vertices and indices containers with the vertex data from the mesh.
		 It should be called somewhere before the vertex and index buffers are created:
		*/


		/*
		An OBJ file consists of positions, normals, texture coordinates and faces. Faces
		consist of an arbitrary amount of vertices, where each vertex refers to a position,
		normal and/or texture coordinate by index. This makes it possible to not just reuse
		entire vertices, but also individual attributes.

		The attrib container holds all of the positions, normals and texture coordinates in
		its attrib.vertices, attrib.normals and attrib.texcoords vectors. The shapes container
		contains all of the separate objects and their faces. Each face consists of an array
		of vertices, and each vertex contains the indices of the position, normal and texture
		coordinate attributes. OBJ models can also define a material and texture per face,
		but we will be ignoring those.

		The err string contains errors and the warn string contains warnings that occurred while
		loading the file, like a missing material definition. Loading only really failed if the
		LoadObj function returns false. As mentioned above, faces in OBJ files can actually contain
		an arbitrary number of vertices, whereas our application can only render triangles. Luckily
		the LoadObj has an optional parameter to automatically triangulate such faces, which is enabled
		by default.
		*/
		tinyobj::attrib_t attrib;
		std::vector<tinyobj::shape_t> shapes;
		std::vector<tinyobj::material_t> materials;
		std::string warn, err;

		if (!tinyobj::LoadObj(&attrib, &shapes, &materials, &warn, &err, MODEL_PATH.c_str()))
		{
			throw std::runtime_error(warn + err);
		}

		/*
		We're going to combine all of the faces in the file into a single model, so just iterate over all
		of the shapes:

		The triangulation feature has already made sure that there are three vertices per face, so we can
		now directly iterate over the vertices and dump them straight into our vertices vector:
		*/
		for (const auto& shape : shapes)
		{
			for (const auto& index : shape.mesh.indices)
			{
				Vertex vertex{};

				/*
				For simplicity, we will assume that every vertex is unique for now, hence the simple
				auto-increment indices. The index variable is of type tinyobj::index_t, which contains
				the vertex_index, normal_index and texcoord_index members. We need to use these indices
				to look up the actual vertex attributes in the attrib arrays:

				Unfortunately the attrib.vertices array is an array of float values instead of something
				like glm::vec3, so you need to multiply the index by 3. Similarly, there are two texture
				coordinate components per entry. The offsets of 0, 1 and 2 are used to access the X, Y
				and Z components, or the U and V components in the case of texture coordinates.
				*/
				vertex.pos =
				{
					attrib.vertices[3 * index.vertex_index + 0],
					attrib.vertices[3 * index.vertex_index + 1],
					attrib.vertices[3 * index.vertex_index + 2],
				};
				/*
				 The OBJ format assumes a coordinate system where a vertical coordinate of 0 means the
				 bottom of the image, however we've uploaded our image into Vulkan in a top to bottom
				 orientation where 0 means the top of the image. Solve this by flipping the vertical
				 component of the texture coordinates:
				*/
				vertex.texCoord =
				{
					attrib.texcoords[2 * index.texcoord_index + 0],
					1.0f - attrib.texcoords[2 * index.texcoord_index + 1],
				};

				vertex.color = { 1.0f, 1.0f, 1.0f };

				/*
				The vertices vector contains a lot of duplicated vertex data, because many vertices are
				included in multiple triangles. We should keep only the unique vertices and use the
				index buffer to reuse them whenever they come up. A straightforward way to implement
				this is to use a map or unordered_map to keep track of the unique vertices and respective
				indices:

				Every time we read a vertex from the OBJ file, we check if we've already seen a vertex with
				the exact same position and texture coordinates before. If not, we add it to vertices and
				store its index in the uniqueVertices container. After that we add the index of the new
				vertex to indices. If we've seen the exact same vertex before, then we look up its index
				in uniqueVertices and store that index in indices.
				*/
				if (uniqueVertices.count(vertex) == 0)
				{
					//This generate unique indices id since it only adds to vector if its not there
					//E.g. - V1: 0, V2: 1, V3: 2, V4 == V1 -> skip this and find key which will return V1: 0
					uniqueVertices[vertex] = static_cast<uint32_t>(vertices.size());
					vertices.push_back(vertex);
				}

				indices.push_back(uniqueVertices[vertex]);
			}
		}
	}

	void createVertexBuffer()
	{
		/*
		The vertex buffer we have right now works correctly, but the memory type that allows us
		to access it from the CPU may not be the most optimal memory type for the graphics card
		itself to read from. The most optimal memory has the VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
		flag and is usually not accessible by the CPU on dedicated graphics cards. we're going to
		create two vertex buffers. One staging buffer in CPU accessible memory to upload the data
		from the vertex array to, and the final vertex buffer in device local memory. We'll then
		use a buffer copy command to move the data from the staging buffer to the actual vertex buffer.

		We're now going to change createVertexBuffer to only use a host visible buffer as temporary
		buffer and use a device local one as actual vertex buffer.
		*/

		VkDeviceSize bufferSize = sizeof(vertices[0]) * vertices.size();
		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;
		/*
		VK_BUFFER_USAGE_TRANSFER_SRC_BIT: Buffer can be used as source in a memory transfer operation.
		VK_BUFFER_USAGE_TRANSFER_DST_BIT: Buffer can be used as destination in a memory transfer operation.
		*/
		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
					 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
					 VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
					 stagingBuffer, stagingBufferMemory);

		/*
		This function allows us to access a region of the specified memory resource defined by an
		offset and size. The offset and size here are 0 and bufferInfo.size, respectively. It is
		also possible to specify the special value VK_WHOLE_SIZE to map all of the memory. The
		second to last parameter can be used to specify flags, but there aren't any available
		yet in the current API. It must be set to the value 0. The last parameter specifies the
		output for the pointer to the mapped memory.
		*/
		void* data;
		vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &data);

		/*
		You can now simply memcpy the vertex data to the mapped memory and unmap it again using
		vkUnmapMemory. Unfortunately the driver may not immediately copy the data into the buffer
		memory, for example because of caching. It is also possible that writes to the buffer are
		not visible in the mapped memory yet. There are two ways to deal with that problem:

		- Use a memory heap that is host coherent, indicated with VK_MEMORY_PROPERTY_HOST_COHERENT_BIT

		- Call vkFlushMappedMemoryRanges after writing to the mapped memory, and call
		vkInvalidateMappedMemoryRanges before reading from the mapped memory

		We went for the first approach, which ensures that the mapped memory always matches the
		contents of the allocated memory. Do keep in mind that this may lead to slightly worse
		performance than explicit flushing

		Flushing memory ranges or using a coherent memory heap means that the driver will be aware
		of our writes to the buffer, but it doesn't mean that they are actually visible on the GPU
		yet. The transfer of data to the GPU is an operation that happens in the background and the
		specification simply tells us that it is guaranteed to be complete as of the next call to
		vkQueueSubmit.
		*/
		memcpy(data, vertices.data(), (size_t)bufferSize);
		vkUnmapMemory(device, stagingBufferMemory);


		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT |
					 VK_BUFFER_USAGE_VERTEX_BUFFER_BIT,
					 VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
					 vertexBuffer, vertexBufferMemory);

		copyBuffer(stagingBuffer, vertexBuffer, bufferSize);

		vkDestroyBuffer(device, stagingBuffer, nullptr);
		vkFreeMemory(device, stagingBufferMemory, nullptr);

		/*
		https://www.quora.com/STL-C++-Why-does-sizeof-return-the-same-value-for-all-vectors-regardless-of-the-type-and-number-of-elements-in-that-vector
		*/
		//std::cout << "Size of void*: " << sizeof(void*) << "\n";
		//std::cout << "Size of vertices[0]: " << sizeof(vertices[0]) << "\n";
		//std::cout << "Size of sizeof(vertices[0]) * vertices.size(): " << sizeof(vertices[0]) * vertices.size() << "\n";
		//std::cout << "Size of sizeof(vertices.size()): " << sizeof(vertices) << "\n";
	}

	void createIndexBuffer()
	{
		/*
		Drawing a rectangle takes two triangles, which means that we need a vertex buffer
		with 6 vertices. The problem is that the data of two vertices needs to be duplicated
		resulting in 50% redundancy. It only gets worse with more complex meshes, where
		vertices are reused in an average number of 3 triangles. The solution to this
		problem is to use an index buffer.

		An index buffer is essentially an array of pointers into the vertex buffer. It allows
		you to reorder the vertex data, and reuse existing data for multiple vertices.
		*/

		/*
		The bufferSize is now equal to the number of indices times the size of the index type,
		either uint16_t or uint32_t
		*/
		VkDeviceSize bufferSize = sizeof(indices[0]) * indices.size();

		/*
		The usage of the indexBuffer should be VK_BUFFER_USAGE_INDEX_BUFFER_BIT instead of
		VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, which makes sense. Other than that, the process
		is exactly the same. We create a staging buffer to copy the contents of indices to
		and then copy it to the final device local index buffer.
		*/
		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;
		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
					 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
					 VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
					 stagingBuffer, stagingBufferMemory);

		void* data;
		vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &data);
		memcpy(data, indices.data(), (size_t)bufferSize);
		vkUnmapMemory(device, stagingBufferMemory);

		createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT |
					 VK_BUFFER_USAGE_INDEX_BUFFER_BIT,
					 VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
					 indexBuffer, indexBufferMemory);

		copyBuffer(stagingBuffer, indexBuffer, bufferSize);

		vkDestroyBuffer(device, stagingBuffer, nullptr);
		vkFreeMemory(device, stagingBufferMemory, nullptr);
	}

	void createUniformBuffers()
	{
		/*
		In the next chapter we'll specify the buffer that contains the UBO data for the shader,
		but we need to create this buffer first. We're going to copy new data to the uniform buffer
		every frame, so it doesn't really make any sense to have a staging buffer. It would just
		add extra overhead in this case and likely degrade performance instead of improving it.

		We should have multiple buffers, because multiple frames may be in flight at the same time
		and we don't want to update the buffer in preparation of the next frame while a previous
		one is still reading from it! We could either have a uniform buffer per frame or
		per swap chain image. However, since we need to refer to the uniform buffer from the
		command buffer that we have per swap chain image, it makes the most sense to also have
		a uniform buffer per swap chain image.
		*/

		VkDeviceSize bufferSize = sizeof(UniformBufferObject);

		uniformBuffers.resize(swapChainImages.size());
		uniformBuffersMemory.resize(swapChainImages.size());

		for (size_t i = 0; i < swapChainImages.size(); i++)
		{
			createBuffer(bufferSize, VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT,
						 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
						 VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
						 uniformBuffers[i], uniformBuffersMemory[i]);

			/*
			We're going to write a separate function that updates the uniform buffer
			with a new transformation every frame, so there will be no vkMapMemory here.
			*/
		}
	}

	void createDescriptorPool()
	{
		/*
		We first need to describe which descriptor types our descriptor sets are going to
		contain and how many of them, using VkDescriptorPoolSize structures.

		Inadequate descriptor pools are a good example of a problem that the validation layers
		will not catch: As of Vulkan 1.1, vkAllocateDescriptorSets may fail with the error code
		VK_ERROR_POOL_OUT_OF_MEMORY if the pool is not sufficiently large, but the driver may also
		try to solve the problem internally. This means that sometimes (depending on hardware,
		pool size and allocation size) the driver will let us get away with an allocation that
		exceeds the limits of our descriptor pool. Other times, vkAllocateDescriptorSets will fail
		and return VK_ERROR_POOL_OUT_OF_MEMORY. This can be particularly frustrating if the allocation
		succeeds on some machines, but fails on others.

		Since Vulkan shifts the responsiblity for the allocation to the driver, it is no longer a strict
		requirement to only allocate as many descriptors of a certain type
		(VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, etc.) as specified by the corresponding descriptorCount
		members for the creation of the descriptor pool. However, it remains best practise to do so, and
		in the future, VK_LAYER_KHRONOS_validation will warn about this type of problem if you enable
		Best Practice Validation.
		https://vulkan.lunarg.com/doc/view/1.1.126.0/windows/best_practices.html
		*/
		std::array<VkDescriptorPoolSize, 2> poolSizes{};
		poolSizes[0].type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
		poolSizes[0].descriptorCount = static_cast<uint32_t>(swapChainImages.size());
		//For image sampler
		poolSizes[1].type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
		poolSizes[1].descriptorCount = static_cast<uint32_t>(swapChainImages.size());

		/*
		We will allocate one of these descriptors for every frame. This pool size structure is referenced
		by the main VkDescriptorPoolCreateInfo:
		*/
		VkDescriptorPoolCreateInfo poolInfo{};
		poolInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;
		poolInfo.poolSizeCount = static_cast<uint32_t>(poolSizes.size());
		poolInfo.pPoolSizes = poolSizes.data();
		/*
		Aside from the maximum number of individual descriptors that are available, we also need
		to specify the maximum number of descriptor sets that may be allocated:
		*/
		poolInfo.maxSets = static_cast<uint32_t>(swapChainImages.size());
		/*
		The structure has an optional flag similar to command pools that determines if individual
		descriptor sets can be freed or not: VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT.
		We're not going to touch the descriptor set after creating it, so we don't need this flag.
		You can leave flags to its default value of 0.
		*/
		//poolInfo.flags = 0;

		if (vkCreateDescriptorPool(device, &poolInfo, nullptr, &descriptorPool) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create descriptor pool!");
		}
	}

	void createDescriptorSets()
	{
		/*
		A descriptor set allocation is described with a VkDescriptorSetAllocateInfo struct.
		You need to specify the descriptor pool to allocate from, the number of descriptor
		sets to allocate, and the descriptor layout to base them on:
		*/
		std::vector<VkDescriptorSetLayout> layouts(swapChainImages.size(), descriptorSetLayout);
		VkDescriptorSetAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO;
		allocInfo.descriptorPool = descriptorPool;
		allocInfo.descriptorSetCount = static_cast<uint32_t>(swapChainImages.size());
		allocInfo.pSetLayouts = layouts.data();

		/*
		In our case we will create one descriptor set for each swap chain image, all with the
		same layout. Unfortunately we do need all the copies of the layout because the next
		function expects an array matching the number of sets.

		You don't need to explicitly clean up descriptor sets, because they will be automatically
		freed when the descriptor pool is destroyed. The call to vkAllocateDescriptorSets will
		allocate descriptor sets, each with one uniform buffer and one combined image sampler descriptor.
		*/
		descriptorSets.resize(swapChainImages.size());
		if (vkAllocateDescriptorSets(device, &allocInfo, descriptorSets.data()) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to allocate descriptor sets!");
		}

		for (size_t i = 0; i < swapChainImages.size(); i++)
		{
			/*
			Descriptors that refer to buffers, like our uniform buffer descriptor, are configured
			with a VkDescriptorBufferInfo struct. This structure specifies the buffer and the region
			within it that contains the data for the descriptor.
			*/
			VkDescriptorBufferInfo bufferInfo{};
			bufferInfo.buffer = uniformBuffers[i];
			bufferInfo.offset = 0;
			/*
			If you're overwriting the whole buffer, like we are in this case, then it is is also
			possible to use the VK_WHOLE_SIZE value for the range.
			*/
			bufferInfo.range = sizeof(UniformBufferObject);

			// bind the actual image and sampler resources to the descriptors in the descriptor set.
			VkDescriptorImageInfo imageInfo{};
			imageInfo.imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
			imageInfo.imageView = textureImageView;
			imageInfo.sampler = textureSampler;

			/*
			The first two fields specify the descriptor set to update and the binding. We gave our
			uniform buffer binding index 0. Remember that descriptors can be arrays, so we also need
			to specify the first index in the array that we want to update. We're not using an array,
			so the index is simply 0.
			*/
			//VkWriteDescriptorSet descriptorWrite{};
			std::array<VkWriteDescriptorSet, 2> descriptorWrites{};

			descriptorWrites[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
			descriptorWrites[0].dstSet = descriptorSets[i];

			descriptorWrites[1].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
			descriptorWrites[1].dstSet = descriptorSets[i];

			/*
			We need to specify the type of descriptor again. It's possible to update multiple
			descriptors at once in an array, starting at index dstArrayElement. The descriptorCount
			field specifies how many array elements you want to update.
			*/
			descriptorWrites[0].dstBinding = 0;
			descriptorWrites[0].dstArrayElement = 0;
			descriptorWrites[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
			descriptorWrites[0].descriptorCount = 1;

			descriptorWrites[1].dstBinding = 1;
			descriptorWrites[1].dstArrayElement = 0;
			descriptorWrites[1].descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
			descriptorWrites[1].descriptorCount = 1;

			/*
			The last field references an array with descriptorCount structs that actually configure
			the descriptors. It depends on the type of descriptor which one of the three you actually
			need to use. The pBufferInfo field is used for descriptors that refer to buffer data,
			pImageInfo is used for descriptors that refer to image data, and pTexelBufferView is
			used for descriptors that refer to buffer views. Our descriptor is based on buffers,
			so we're using pBufferInfo.
			*/
			descriptorWrites[0].pBufferInfo = &bufferInfo;
			descriptorWrites[0].pImageInfo = nullptr; // Optional
			descriptorWrites[0].pTexelBufferView = nullptr; // Optional

			/*
			The descriptors must be updated with this image info, just like the buffer.
			This time we're using the pImageInfo array instead of pBufferInfo
			*/
			descriptorWrites[1].pImageInfo = &imageInfo;

			/*
			The updates are applied using vkUpdateDescriptorSets. It accepts two kinds of arrays
			as parameters: an array of VkWriteDescriptorSet and an array of VkCopyDescriptorSet.
			The latter can be used to copy descriptors to each other, as its name implies.
			*/
			vkUpdateDescriptorSets(device, static_cast<uint32_t>(descriptorWrites.size()), descriptorWrites.data(), 0, nullptr);
		}

		/*
		As some of the structures and function calls hinted at, it is actually possible to
		bind multiple descriptor sets simultaneously. You need to specify a descriptor layout
		for each descriptor set when creating the pipeline layout. Shaders can then reference
		specific descriptor sets like this:

		layout(set = 0, binding = 0) uniform UniformBufferObject { ... }

		You can use this feature to put descriptors that vary per-object and descriptors that
		are shared into separate descriptor sets. In that case you avoid rebinding most of the
		descriptors across draw calls which is potentially more efficient.
		*/
	}

	VkCommandBuffer beginSingleTimeCommands()
	{
		/*
		Memory transfer operations are executed using command buffers, just like drawing commands.
		Therefore we must first allocate a temporary command buffer. You may wish to create a
		separate command pool for these kinds of short-lived buffers, because the implementation
		may be able to apply memory allocation optimizations. You should use the
		VK_COMMAND_POOL_CREATE_TRANSIENT_BIT flag during command pool generation in that case.
		*/
		VkCommandBufferAllocateInfo allocInfo{};
		allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
		allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
		allocInfo.commandPool = commandPool;
		allocInfo.commandBufferCount = 1;

		VkCommandBuffer commandBuffer;
		vkAllocateCommandBuffers(device, &allocInfo, &commandBuffer);

		/*
		We're only going to use the command buffer once and wait with returning from the function
		until the copy operation has finished executing. It's good practice to tell the driver
		about our intent using VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT.
		*/
		VkCommandBufferBeginInfo beginInfo{};
		beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
		beginInfo.flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT;

		vkBeginCommandBuffer(commandBuffer, &beginInfo);

		return commandBuffer;
	}

	void endSingleTimeCommands(VkCommandBuffer commandBuffer)
	{
		vkEndCommandBuffer(commandBuffer);

		VkSubmitInfo submitInfo{};
		submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
		submitInfo.commandBufferCount = 1;
		submitInfo.pCommandBuffers = &commandBuffer;

		/*
		Unlike the draw commands, there are no events we need to wait on this time.
		We just want to execute the transfer on the buffers immediately. There are
		again two possible ways to wait on this transfer to complete. We could use
		a fence and wait with vkWaitForFences, or simply wait for the transfer queue
		to become idle with vkQueueWaitIdle. A fence would allow you to schedule
		multiple transfers simultaneously and wait for all of them complete, instead
		of executing one at a time. That may give the driver more opportunities to optimize.
		*/
		vkQueueSubmit(graphicsQueue, 1, &submitInfo, VK_NULL_HANDLE);
		vkQueueWaitIdle(graphicsQueue);

		vkFreeCommandBuffers(device, commandPool, 1, &commandBuffer);
	}

	void copyBuffer(VkBuffer srcBuffer, VkBuffer dstBuffer, VkDeviceSize size)
	{
		/*
		The vertexBuffer is now allocated from a memory type that is device local,
		which generally means that we're not able to use vkMapMemory. However, we
		can copy data from the stagingBuffer to the vertexBuffer. We have to indicate
		that we intend to do that by specifying the transfer source flag for the
		stagingBuffer and the transfer destination flag for the vertexBuffer, along with
		the vertex buffer usage flag.

		We're now going to write a function to copy the contents from one buffer to another,
		called copyBuffer.
		*/

		VkCommandBuffer commandBuffer = beginSingleTimeCommands();

		/*
		Contents of buffers are transferred using the vkCmdCopyBuffer command.
		It takes the source and destination buffers as arguments, and an array
		of regions to copy. The regions are defined in VkBufferCopy structs and
		consist of a source buffer offset, destination buffer offset and size.
		It is not possible to specify VK_WHOLE_SIZE here, unlike the vkMapMemory command.
		*/
		VkBufferCopy copyRegion{};
		//copyRegion.srcOffset = 0; // Optional
		//copyRegion.dstOffset = 0; // Optional
		copyRegion.size = size;
		vkCmdCopyBuffer(commandBuffer, srcBuffer, dstBuffer, 1, &copyRegion);

		endSingleTimeCommands(commandBuffer);
	}

	void copyBufferToImage(VkBuffer buffer, VkImage image, uint32_t width, uint32_t height)
	{
		VkCommandBuffer commandBuffer = beginSingleTimeCommands();

		/*
		The bufferOffset specifies the byte offset in the buffer at which the pixel values start.
		The bufferRowLength and bufferImageHeight fields specify how the pixels are laid out in
		memory. For example, you could have some padding bytes between rows of the image. Specifying
		0 for both indicates that the pixels are simply tightly packed like they are in our case.
		The imageSubresource, imageOffset and imageExtent fields indicate to which part of the image
		we want to copy the pixels.
		*/
		VkBufferImageCopy region{};
		region.bufferOffset = 0;
		region.bufferRowLength = 0;
		region.bufferImageHeight = 0;

		region.imageSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		region.imageSubresource.mipLevel = 0;
		region.imageSubresource.baseArrayLayer = 0;
		region.imageSubresource.layerCount = 1;

		region.imageOffset = { 0, 0, 0 };
		region.imageExtent = { width, height, 1 };

		/*
		The fourth parameter indicates which layout the image is currently using. I'm assuming here
		that the image has already been transitioned to the layout that is optimal for copying pixels to.
		Right now we're only copying one chunk of pixels to the whole image, but it's possible to
		specify an array of VkBufferImageCopy to perform many different copies from this buffer to
		the image in one operation.
		*/
		vkCmdCopyBufferToImage(
			commandBuffer,
			buffer,
			image,
			VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
			1,
			&region
		);

		endSingleTimeCommands(commandBuffer);
	}

	void transitionImageLayout(VkImage image, VkFormat format, VkImageLayout oldLayout, VkImageLayout newLayout)
	{
		VkCommandBuffer commandBuffer = beginSingleTimeCommands();

		VkPipelineStageFlags sourceStage;
		VkPipelineStageFlags destinationStage;

		/*
		One of the most common ways to perform layout transitions is using an image memory barrier.
		A pipeline barrier like that is generally used to synchronize access to resources, like
		ensuring that a write to a buffer completes before reading from it, but it can also be
		used to transition image layouts and transfer queue family ownership when
		VK_SHARING_MODE_EXCLUSIVE is used. There is an equivalent buffer memory barrier to do this
		for buffers
		*/
		VkImageMemoryBarrier barrier{};
		barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
		/*
		The first two fields specify layout transition. It is possible to use VK_IMAGE_LAYOUT_UNDEFINED
		as oldLayout if you don't care about the existing contents of the image.
		*/
		barrier.oldLayout = oldLayout;
		barrier.newLayout = newLayout;
		/*
		If you are using the barrier to transfer queue family ownership, then these two fields should be
		the indices of the queue families. They must be set to VK_QUEUE_FAMILY_IGNORED if you don't want
		to do this (not the default value!).
		*/
		barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;

		/*
		The image and subresourceRange specify the image that is affected and the specific
		part of the image. Our image is not an array and does not have mipmapping levels,
		so only one level and layer are specified.
		*/
		barrier.image = image;
		//barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		if (newLayout == VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL)
		{
			barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_DEPTH_BIT;

			if (hasStencilComponent(format))
			{
				barrier.subresourceRange.aspectMask |= VK_IMAGE_ASPECT_STENCIL_BIT;
			}
		}
		else
		{
			barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		}
		barrier.subresourceRange.baseMipLevel = 0;
		barrier.subresourceRange.levelCount = mipLevels;
		barrier.subresourceRange.baseArrayLayer = 0;
		barrier.subresourceRange.layerCount = 1;
		/*
		Barriers are primarily used for synchronization purposes, so you must specify which
		types of operations that involve the resource must happen before the barrier, and
		which operations that involve the resource must wait on the barrier. We need to do
		that despite already using vkQueueWaitIdle to manually synchronize. The right values
		depend on the old and new layout

		There are two transitions we need to handle:

		Undefined -> transfer destination: transfer writes that don't need to wait on anything

		Transfer destination -> shader reading: shader reads should wait on transfer writes,
		specifically the shader reads in the fragment shader, because that's where we're going
		to use the texture

		As you can see in the aforementioned table, transfer writes must occur in the pipeline
		transfer stage. Since the writes don't have to wait on anything, you may specify an empty
		access mask and the earliest possible pipeline stage VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT
		for the pre-barrier operations. It should be noted that VK_PIPELINE_STAGE_TRANSFER_BIT
		is not a real stage within the graphics and compute pipelines. It is more of a pseudo-stage
		where transfers happen. See the documentation for more information and other examples of
		pseudo-stages.

		The image will be written in the same pipeline stage and subsequently read by the fragment
		shader, which is why we specify shader reading access in the fragment shader pipeline stage.

		One thing to note is that command buffer submission results in implicit VK_ACCESS_HOST_WRITE_BIT
		synchronization at the beginning. Since the transitionImageLayout function executes a command
		buffer with only a single command, you could use this implicit synchronization and set
		srcAccessMask to 0 if you ever needed a VK_ACCESS_HOST_WRITE_BIT dependency in a layout
		transition. It's up to you if you want to be explicit about it or not, but I'm personally not
		a fan of relying on these OpenGL-like "hidden" operations.

		There is actually a special type of image layout that supports all operations,
		VK_IMAGE_LAYOUT_GENERAL. The problem with it, of course, is that it doesn't necessarily offer
		the best performance for any operation. It is required for some special cases, like using an
		image as both input and output, or for reading an image after it has left the preinitialized
		layout.
		*/
		if (oldLayout == VK_IMAGE_LAYOUT_UNDEFINED && newLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL)
		{
			barrier.srcAccessMask = 0;
			barrier.dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;

			sourceStage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
			destinationStage = VK_PIPELINE_STAGE_TRANSFER_BIT;
		}
		else if (oldLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL && newLayout == VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL)
		{
			barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

			sourceStage = VK_PIPELINE_STAGE_TRANSFER_BIT;
			destinationStage = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
		}
		else if (oldLayout == VK_IMAGE_LAYOUT_UNDEFINED && newLayout == VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL)
		{
			barrier.srcAccessMask = 0;
			barrier.dstAccessMask = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT | VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;

			/*
			The depth buffer will be read from to perform depth tests to see if a fragment
			is visible, and will be written to when a new fragment is drawn. The reading
			happens in the VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT stage and the writing
			in the VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT. You should pick the earliest
			pipeline stage that matches the specified operations, so that it is ready for
			usage as depth attachment when it needs to be.
			*/
			sourceStage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
			destinationStage = VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
		}
		else
		{
			throw std::invalid_argument("unsupported layout transition!");
		}


		/*
		All types of pipeline barriers are submitted using the same function. The first parameter
		after the command buffer specifies in which pipeline stage the operations occur that
		should happen before the barrier. The second parameter specifies the pipeline stage in
		which operations will wait on the barrier. The pipeline stages that you are allowed to
		specify before and after the barrier depend on how you use the resource before and after
		the barrier. The allowed values are listed in this table of the specification. For example,
		if you're going to read from a uniform after the barrier, you would specify a usage of
		VK_ACCESS_UNIFORM_READ_BIT and the earliest shader that will read from the uniform as
		pipeline stage, for example VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT. It would not make sense
		to specify a non-shader pipeline stage for this type of usage and the validation layers will
		warn you when you specify a pipeline stage that does not match the type of usage.

		The third parameter is either 0 or VK_DEPENDENCY_BY_REGION_BIT. The latter turns the barrier
		into a per-region condition. That means that the implementation is allowed to already begin
		reading from the parts of a resource that were written so far, for example.

		The last three pairs of parameters reference arrays of pipeline barriers of the three available
		types: memory barriers, buffer memory barriers, and image memory barriers like the one we're
		using here. Note that we're not using the VkFormat parameter yet, but we'll be using that one
		for special transitions in the depth buffer chapter.
		*/
		vkCmdPipelineBarrier(
			commandBuffer,
			sourceStage, destinationStage,
			0,
			0, nullptr,
			0, nullptr,
			1, &barrier
		);

		endSingleTimeCommands(commandBuffer);
	}

	uint32_t findMemoryType(uint32_t typeFilter, VkMemoryPropertyFlags properties)
	{
		/*
		query info about the available types of memory

		The VkPhysicalDeviceMemoryProperties structure has two arrays memoryTypes and memoryHeaps.
		Memory heaps are distinct memory resources like dedicated VRAM and swap space in RAM for
		when VRAM runs out. The different types of memory exist within these heaps. Right now we'll
		only concern ourselves with the type of memory and not the heap it comes from, but you can
		imagine that this can affect performance.
		*/
		VkPhysicalDeviceMemoryProperties memProperties;
		vkGetPhysicalDeviceMemoryProperties(physicalDevice, &memProperties);

		/*
		The typeFilter parameter will be used to specify the bit field of memory types that are suitable.
		That means that we can find the index of a suitable memory type by simply iterating over them
		and checking if the corresponding bit is set to 1.

		However, we're not just interested in a memory type that is suitable for the vertex buffer.
		We also need to be able to write our vertex data to that memory. The memoryTypes array
		consists of VkMemoryType structs that specify the heap and properties of each type of memory.
		The properties define special features of the memory, like being able to map it so we can
		write to it from the CPU. This property is indicated with VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT,
		but we also need to use the VK_MEMORY_PROPERTY_HOST_COHERENT_BIT property. We'll see why when
		we map the memory.
		*/
		for (uint32_t i = 0; i < memProperties.memoryTypeCount; i++)
		{
			/*
			We may have more than one desirable property, so we should check if the result of
			the bitwise AND is not just non-zero, but equal to the desired properties bit field.
			If there is a memory type suitable for the buffer that also has all of the properties
			we need, then we return its index, otherwise we throw an exception.
			*/
			if ((typeFilter & (1 << i)) && (memProperties.memoryTypes[i].propertyFlags & properties) == properties)
			{
				return i;
			}
		}

		throw std::runtime_error("failed to find suitable memory type!");
	}

	void cleanupSwapChain()
	{
		vkDestroyImageView(device, colorImageView, nullptr);
		vkDestroyImage(device, colorImage, nullptr);
		vkFreeMemory(device, colorImageMemory, nullptr);

		vkDestroyImageView(device, depthImageView, nullptr);
		vkDestroyImage(device, depthImage, nullptr);
		vkFreeMemory(device, depthImageMemory, nullptr);

		/*
		The uniform data will be used for all draw calls, so the buffer containing it should
		only be destroyed when we stop rendering. Since it also depends on the number of
		swap chain images, which could change after a recreation
		*/
		for (size_t i = 0; i < swapChainImages.size(); i++)
		{
			vkDestroyBuffer(device, uniformBuffers[i], nullptr);
			vkFreeMemory(device, uniformBuffersMemory[i], nullptr);
		}

		vkDestroyDescriptorPool(device, descriptorPool, nullptr);

		for (size_t i = 0; i < swapChainFramebuffers.size(); i++)
		{
			vkDestroyFramebuffer(device, swapChainFramebuffers[i], nullptr);
		}

		/*
		We could recreate the command pool from scratch, but that is rather wasteful.
		Instead I've opted to clean up the existing command buffers with the vkFreeCommandBuffers
		function. This way we can reuse the existing pool to allocate the new command buffers.
		*/
		vkFreeCommandBuffers(device, commandPool, static_cast<uint32_t>(commandBuffers.size()), commandBuffers.data());

		vkDestroyPipeline(device, graphicsPipeline, nullptr);
		vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
		vkDestroyRenderPass(device, renderPass, nullptr);

		/*
		Unlike images, the image views were explicitly created by us, so we need to add
		a similar loop to destroy them again at the end of the program:
		*/
		for (size_t i = 0; i < swapChainImageViews.size(); i++)
		{
			vkDestroyImageView(device, swapChainImageViews[i], nullptr);
		}

		vkDestroySwapchainKHR(device, swapChain, nullptr);
	}

	void recreateSwapChain()
	{
		/*
		The application we have now successfully draws a triangle, but there are some
		circumstances that it isn't handling properly yet. It is possible for the window
		surface to change such that the swap chain is no longer compatible with it. One
		of the reasons that could cause this to happen is the size of the window changing.
		We have to catch these events and recreate the swap chain.
		*/

		/*
		We first call vkDeviceWaitIdle, because just like in the last chapter, we shouldn't
		touch resources that may still be in use. Obviously, the first thing we'll have to
		do is recreate the swap chain itself. The image views need to be recreated because
		they are based directly on the swap chain images. The render pass needs to be recreated
		because it depends on the format of the swap chain images. It is rare for the swap
		chain image format to change during an operation like a window resize, but it should
		still be handled. Viewport and scissor rectangle size is specified during graphics
		pipeline creation, so the pipeline also needs to be rebuilt. It is possible to avoid
		this by using dynamic state for the viewports and scissor rectangles. Finally, the
		framebuffers and command buffers also directly depend on the swap chain images.
		*/

		/*
		Note that in chooseSwapExtent we already query the new window resolution to make sure
		that the swap chain images have the (new) right size, so there's no need to modify
		chooseSwapExtent (remember that we already had to use glfwGetFramebufferSize get the
		resolution of the surface in pixels when creating the swap chain).

		That's all it takes to recreate the swap chain! However, the disadvantage of this approach
		is that we need to stop all rendering before creating the new swap chain. It is possible to
		create a new swap chain while drawing commands on an image from the old swap chain are still
		in-flight. You need to pass the previous swap chain to the oldSwapChain field in the
		VkSwapchainCreateInfoKHR struct and destroy the old swap chain as soon as you've finished
		using it.
		*/

		int width = 0, height = 0;
		glfwGetFramebufferSize(window, &width, &height);
		while (width == 0 || height == 0)
		{
			glfwGetFramebufferSize(window, &width, &height);
			glfwWaitEvents();
		}

		vkDeviceWaitIdle(device);

		cleanupSwapChain();

		createSwapChain();
		createImageViews();
		createRenderPass();
		createGraphicsPipeline();
		createColorResources();
		createDepthResources();
		createFramebuffers();
		createUniformBuffers();
		createDescriptorPool();
		createDescriptorSets();
		createCommandBuffers();
	}

	bool isDeviceSuitable(VkPhysicalDevice InDevice)
	{
		//The support for optional features like texture compression, 64 bit floats and
		//multi viewport rendering(useful for VR) can be queried using vkGetPhysicalDeviceFeatures

		//VkPhysicalDeviceProperties deviceProperties{};
		//vkGetPhysicalDeviceProperties(InDevice, &deviceProperties);
		//std::cout << "vkDeviceProp : " << deviceProperties.deviceName << '\n';

		QueueFamilyIndices indices = findQueueFamilies(InDevice);
		bool extensionsSupported = checkDeviceExtensionSupport(InDevice);

		bool swapChainAdequate = false;
		if (extensionsSupported)
		{
			SwapChainSupportDetails swapChainSupport = querySwapChainSupport(InDevice);
			swapChainAdequate = !swapChainSupport.formats.empty() && !swapChainSupport.presentModes.empty();
		}

		/*
		The vkGetPhysicalDeviceFeatures repurposes the VkPhysicalDeviceFeatures struct to indicate
		which features are supported rather than requested by setting the boolean values.

		Instead of enforcing the availability of anisotropic filtering, it's also possible to simply
		not use it by conditionally setting:

		samplerInfo.anisotropyEnable = VK_FALSE;
		samplerInfo.maxAnisotropy = 1.0f;
		*/
		VkPhysicalDeviceFeatures supportedFeatures;
		vkGetPhysicalDeviceFeatures(InDevice, &supportedFeatures);
		/*
		anisotropic filtering is actually an optional device feature
		even though it is very unlikely that a modern graphics card will not support it,
		we should check if it is available:
		*/
		return indices.isComplete() && extensionsSupported && swapChainAdequate && supportedFeatures.samplerAnisotropy;

		/*
		//As an example, let’s say we consider our application only usable for dedicated
		//graphics cards that support geometry shaders.Then the isDeviceSuitable
		//function would look like this:

		VkPhysicalDeviceProperties deviceProperties;
		VkPhysicalDeviceFeatures deviceFeatures;
		vkGetPhysicalDeviceProperties(InDevice, &deviceProperties);
		vkGetPhysicalDeviceFeatures(InDevice, &deviceFeatures);
		return deviceProperties.deviceType == VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU && deviceFeatures.geometryShader;
		*/

		//Or

		/*
		//Instead of just checking if a InDevice is suitable or not and going with the first one,
		//you could also give each InDevice a score and pick the highest one. That way you
		//could favor a dedicated graphics card by giving it a higher score, but fall back
		//to an integrated GPU if that’s the only available one. You could implement
		//something like that as follows:

		// Use an ordered map to automatically sort candidates by increasing score
		std::multimap<int, VkPhysicalDevice> candidates;
		for (const auto& InDevice : physicalDevices)
		{
			int score = rateDeviceSuitability(InDevice);
			candidates.insert(std::make_pair(score, InDevice));
			// Check if the best candidate is suitable at all
			if (candidates.rbegin()->first > 0)
			{
				physicalDevice = candidates.rbegin()->second;
			}
			else
			{
				throw std::runtime_error("failed to find a suitable GPU!");
			}
		}
		*/
	}

	bool checkDeviceExtensionSupport(VkPhysicalDevice InDevice)
	{
		uint32_t extensionCount;
		vkEnumerateDeviceExtensionProperties(InDevice, nullptr, &extensionCount, nullptr);

		std::vector<VkExtensionProperties> availableExtensions(extensionCount);
		vkEnumerateDeviceExtensionProperties(InDevice, nullptr, &extensionCount, availableExtensions.data());

		std::set<std::string> requiredExtensions(g_deviceExtensions.begin(), g_deviceExtensions.end());

		for (const auto& extension : availableExtensions)
		{
			requiredExtensions.erase(extension.extensionName);
		}

		return requiredExtensions.empty();
	}

	int rateDeviceSuitability(VkPhysicalDevice InDevice)
	{
		VkPhysicalDeviceProperties deviceProperties;
		VkPhysicalDeviceFeatures deviceFeatures;
		vkGetPhysicalDeviceProperties(InDevice, &deviceProperties);
		vkGetPhysicalDeviceFeatures(InDevice, &deviceFeatures);

		int score = 0;
		// Discrete GPUs have a significant performance advantage
		if (deviceProperties.deviceType == VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU)
		{
			score += 1000;
		}

		// Maximum possible size of textures affects graphics quality
		score += deviceProperties.limits.maxImageDimension2D;

		// Application can't function without geometry shaders
		if (!deviceFeatures.geometryShader)
		{
			return 0;
		}
		//std::cout << "vkDeviceProp : " << deviceProperties.deviceName << " : " << score << '\n';
		return score;
	}

	void populateDebugMessengerCreateInfo(VkDebugUtilsMessengerCreateInfoEXT& createInfo)
	{
		createInfo = {};
		createInfo.sType =
			VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT;
		createInfo.messageSeverity =
			VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT |
			VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT |
			VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT;
		createInfo.messageType =
			VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT |
			VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT |
			VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT;
		createInfo.pfnUserCallback = debugCallback;
		createInfo.pUserData = nullptr; // Optional
	}

	static VKAPI_ATTR VkBool32 VKAPI_CALL debugCallback
	(
		VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity,
		VkDebugUtilsMessageTypeFlagsEXT messageType,
		const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData,
		void* pUserData
	)
	{
		/* Message Severity */

		//VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT: Diagnostic message

		//VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT : Informational message
		//like the creation of a resource

		//VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT : Message about
		//behavior that is not necessarily an error, but very likely a bug in your
		//application

		//VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT : Message about
		//behavior that is invalid and may cause crashes

		//Teena - Example of using messageSeverity type to enable message print out
		if (messageSeverity >= VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT)
		{
			// Message is important enough to show
		}

		/* Message Type */
		//VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT: Some event has happened
		//that is unrelated to the specification or performance

		//VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT : Something has
		//happened that violates the specification or indicates a possible mistake

		//VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT : Potential nonoptimal use of Vulkan

		/* pCallbackData */
		//pMessage: The debug message as a null - terminated string
		//pObjects : Array of Vulkan object handles related to the message
		//objectCount : Number of objects in array

		std::cerr << "validation layer: " << pCallbackData->pMessage << std::endl;
		return VK_FALSE;
	}

	VkSurfaceFormatKHR chooseSwapSurfaceFormat(const std::vector<VkSurfaceFormatKHR>& availableFormats)
	{
		/*
		//Each VkSurfaceFormatKHR entry contains a format and a colorSpace member.
		//The format member specifies the color channels and types.
		//For example, VK_FORMAT_B8G8R8A8_SRGB means that we store the B, G, R and alpha channels
		//in that order with an 8 bit unsigned integer for a total of 32 bits per pixel.
		//The colorSpace member indicates if the SRGB color space is supported or not using
		//the VK_COLOR_SPACE_SRGB_NONLINEAR_KHR flag.
		//Note that this flag used to be called VK_COLORSPACE_SRGB_NONLINEAR_KHR
		//in old versions of the specification.

		//For the color space we'll use SRGB if it is available, because it results in more accurate
		//perceived colors. It is also pretty much the standard color space for images, like the
		//textures we'll use later on.Because of that we should also use an SRGB color format,
		//of which one of the most common ones is VK_FORMAT_B8G8R8A8_SRGB.
		*/

		for (const auto& availableFormat : availableFormats)
		{
			if (availableFormat.format == VK_FORMAT_B8G8R8A8_SRGB && availableFormat.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR)
			{
				return availableFormat;
			}
		}

		//Return first format if no suitable format that can fit the requirement
		//Alternative: get the next best thing
		return availableFormats[0];
	}

	VkPresentModeKHR chooseSwapPresentMode(const std::vector<VkPresentModeKHR>& availablePresentModes)
	{
		/*
		//The presentation mode is arguably the most important setting for the swap chain,
		//because it represents the actual conditions for showing images to the screen.
		//There are four possible modes available in Vulkan :

		//VK_PRESENT_MODE_IMMEDIATE_KHR: Images submitted by your application are transferred
		//to the screen right away, which may result in tearing.

		//VK_PRESENT_MODE_FIFO_KHR : The swap chain is a queue where the display takes an image
		//from the front of the queue when the display is refreshed and the program inserts
		//rendered images at the back of the queue.If the queue is full then the program has to wait.
		//This is most similar to vertical sync as found in modern games.
		//The moment that the display is refreshed is known as "vertical blank".

		//VK_PRESENT_MODE_FIFO_RELAXED_KHR : This mode only differs from the previous one if the
		//application is late and the queue was empty at the last vertical blank.
		//Instead of waiting for the next vertical blank, the image is transferred right away when
		//it finally arrives.This may result in visible tearing.

		//VK_PRESENT_MODE_MAILBOX_KHR : This is another variation of the second mode.
		//Instead of blocking the application when the queue is full, the images that
		//are already queued are simply replaced with the newer ones.This mode can be
		//used to render frames as fast as possible while still avoiding tearing,
		//resulting in fewer latency issues than standard vertical sync.
		//This is commonly known as "triple buffering", although the existence of three buffers
		//alone does not necessarily mean that the framerate is unlocked.

		//Only the VK_PRESENT_MODE_FIFO_KHR mode is guaranteed to be available,
		//so we'll again have to write a function that looks for the best mode that is available:

		//VK_PRESENT_MODE_MAILBOX_KHR is a very nice trade-off if energy usage is not a concern.
		//It allows us to avoid tearing while still maintaining a fairly low latency by rendering
		//new images that are as up-to-date as possible right until the vertical blank. On mobile
		//physicalDevices, where energy usage is more important, you will probably want to use
		//VK_PRESENT_MODE_FIFO_KHR instead. Now, let's look through the list to see if
		//VK_PRESENT_MODE_MAILBOX_KHR is available:
		*/

		for (const auto& availablePresentMode : availablePresentModes)
		{
			if (availablePresentMode == VK_PRESENT_MODE_MAILBOX_KHR)
			{
				std::cout << "VK_PRESENT_MODE_MAILBOX_KHR" << "\n";
				return availablePresentMode;
			}
		}

		std::cout << "VK_PRESENT_MODE_FIFO_KHR" << "\n";
		return VK_PRESENT_MODE_FIFO_KHR;
	}

	VkExtent2D chooseSwapExtent(const VkSurfaceCapabilitiesKHR& capabilities)
	{
		/*
		The swap extent is the resolution of the swap chain images and it's almost always exactly
		equal to the resolution of the window that we're drawing to in pixels (more on that in a moment).
		The range of the possible resolutions is defined in the VkSurfaceCapabilitiesKHR structure.
		Vulkan tells us to match the resolution of the window by setting the width and height in the
		currentExtent member. However, some window managers do allow us to differ here and this is
		indicated by setting the width and height in currentExtent to a special value: the maximum value
		of uint32_t. In that case we'll pick the resolution that best matches the window within the
		minImageExtent and maxImageExtent bounds. But we must specify the resolution in the correct unit.

		GLFW uses two units when measuring sizes: pixels and screen coordinates. For example, the
		resolution {WIDTH, HEIGHT} that we specified earlier when creating the window is measured in
		screen coordinates. But Vulkan works with pixels, so the swap chain extent must be specified
		in pixels as well. Unfortunately, if you are using a high DPI display (like Apple's Retina display),
		screen coordinates don't correspond to pixels. Instead, due to the higher pixel density,
		the resolution of the window in pixel will be larger than the resolution in screen coordinates.
		So if Vulkan doesn't fix the swap extent for us, we can't just use the original {WIDTH, HEIGHT}.
		Instead, we must use glfwGetFramebufferSize to query the resolution of the window in pixel before
		matching it against the minimum and maximum image extent.
		*/

		if (capabilities.currentExtent.width != UINT32_MAX)
		{
			return capabilities.currentExtent;
		}
		else
		{
			int width, height;
			glfwGetFramebufferSize(window, &width, &height);

			VkExtent2D actualExtent = {
				static_cast<uint32_t>(width),
				static_cast<uint32_t>(height)
			};

			actualExtent.width = std::clamp(actualExtent.width, capabilities.minImageExtent.width, capabilities.maxImageExtent.width);
			actualExtent.height = std::clamp(actualExtent.height, capabilities.minImageExtent.height, capabilities.maxImageExtent.height);

			return actualExtent;
		}
	}

	VkShaderModule createShaderModule(const std::vector<char>& code)
	{
		/*
		The function will take a buffer with the bytecode as parameter
		and create a VkShaderModule from it. Creating a shader module is
		simple, we only need to specify a pointer to the buffer with the
		bytecode and the length of it. This information is specified in a
		VkShaderModuleCreateInfo structure. The one catch is that the size
		of the bytecode is specified in bytes, but the bytecode pointer is
		a uint32_t pointer rather than a char pointer. Therefore we will
		need to cast the pointer with reinterpret_cast as shown below.
		When you perform a cast like this, you also need to ensure that the
		data satisfies the alignment requirements of uint32_t. Lucky for us,
		the data is stored in an std::vector where the default allocator
		already ensures that the data satisfies the worst case alignment requirements.

		alignment: https://stackoverflow.com/questions/8456236/how-is-a-vectors-data-aligned
		*/

		VkShaderModuleCreateInfo createInfo{};
		createInfo.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;
		createInfo.codeSize = code.size();
		createInfo.pCode = reinterpret_cast<const uint32_t*>(code.data());

		VkShaderModule shaderModule;
		if (vkCreateShaderModule(device, &createInfo, nullptr, &shaderModule) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to create shader module!");
		}

		return shaderModule;
	}

	bool checkValidationLayerSupport()
	{
		uint32_t layerCount;
		vkEnumerateInstanceLayerProperties(&layerCount, nullptr);
		std::vector<VkLayerProperties> availableLayers(layerCount);
		vkEnumerateInstanceLayerProperties(&layerCount, availableLayers.data());

		for (const char* layerName : g_validationLayers)
		{
			bool layerFound = false;
			//std::cout << "Available layerProperties : " << '\n';
			for (const auto& layerProperties : availableLayers)
			{

				//std::cout << "layerProperties : " << layerProperties.layerName << '\n';
				if (strcmp(layerName, layerProperties.layerName) == 0)
				{
					layerFound = true;
					break;
				}
			}
			if (!layerFound)
			{
				return false;
			}
		}
		return true;

	}

	double clockToMilliseconds(clock_t ticks)
	{
		// units/(units/time) => time (seconds) * 1000 = milliseconds
		return (ticks / (double)CLOCKS_PER_SEC)*1000.0;
	}

	//clock_t deltaTime = 0;
	//unsigned int frames = 0;
	//double  frameRate = 30;
	//double  averageFrameTimeMilliseconds = 33.333;

	clock_t current_ticks, delta_ticks;
	clock_t fps = 0;

	float fpsLimit = 30;

	void mainLoop()
	{
		while (!glfwWindowShouldClose(window))
		{
			//current_ticks = clock();

			//static std::chrono::time_point<std::chrono::steady_clock> oldTime = std::chrono::high_resolution_clock::now();
			//static int fps; fps++;
			auto oldTime = glfwGetTime();

			glfwPollEvents();
			drawFrame();

			auto newTime = glfwGetTime();

			auto delta = newTime - oldTime;

			auto sleepTime = (1000 / fpsLimit) - delta;

			std::chrono::duration<double, std::milli> elapsed(sleepTime);

			//std::cout << "elapsed: " << elapsed.count() << "\n";
			//std::cout << "delta: " << delta << " - (1000 / fpsLimit): " << (1000 / fpsLimit) << " - sleepTime: " << (long long)sleepTime << "\n";

			//std::this_thread::sleep_for(std::chrono::milliseconds((long long)(sleepTime)));
			//std::this_thread::sleep_for(elapsed);

			//glfw

			//Sleep(sleepTime);

			/*
			if (std::chrono::duration_cast<std::chrono::seconds>(std::chrono::high_resolution_clock::now() - oldTime) >= std::chrono::seconds{ 1 })
			{
				oldTime = std::chrono::high_resolution_clock::now();
				std::cout << "FPS: " << fps << std::endl;
				fps = 0;
			}
			*/

			/*
			delta_ticks = clock() - current_ticks; //the time, in ms, that took to render the scene
			if (delta_ticks > 0)
				fps = CLOCKS_PER_SEC / delta_ticks;
			std::cout << fps << "\n";
			*/

			/*
			//clock_t beginFrame = clock();
			//Put your render function here
			//clock_t endFrame = clock();

			//deltaTime += endFrame - beginFrame;
			//frames++;

			//if you really want FPS
			if (clockToMilliseconds(deltaTime) > 1000.0)
			{ //every second
				frameRate = (double)frames*0.5 + frameRate * 0.5; //more stable
				frames = 0;
				deltaTime -= CLOCKS_PER_SEC;
				averageFrameTimeMilliseconds = 1000.0 / (frameRate == 0 ? 0.001 : frameRate);
				bool vsync = false;
				if (vsync)
					std::cout << "FrameTime was:" << averageFrameTimeMilliseconds << std::endl;
				else
					std::cout << "CPU time was:" << averageFrameTimeMilliseconds << std::endl;
			}
			*/
		}

		vkDeviceWaitIdle(device);
	}

	void drawFrame()
	{
		//Disabling fences seems to improve FPS

		/*
		The drawFrame function will perform the following operations:

		- Acquire an image from the swap chain
		- Execute the command buffer with that image as attachment in the framebuffer
		- Return the image to the swap chain for presentation

		Each of these events is set in motion using a single function call, but they
		are executed asynchronously. The function calls will return before the operations
		are actually finished and the order of execution is also undefined. That is
		unfortunate, because each of the operations depends on the previous one finishing.

		There are two ways of synchronizing swap chain events: fences and semaphores.
		They're both objects that can be used for coordinating operations by having one
		operation signal and another operation wait for a fence or semaphore to go from
		the unsignaled to signaled state.

		The difference is that the state of fences can be accessed from your program using
		calls like vkWaitForFences and semaphores cannot be. Fences are mainly designed to
		synchronize your application itself with rendering operation, whereas semaphores are
		used to synchronize operations within or across command queues. We want to synchronize
		the queue operations of draw commands and presentation, which makes semaphores the best fit.

		CPU-GPU (using fences) and GPU-GPU (using semaphores) synchronization mechanisms
		*/

		/*
		The vkWaitForFences function takes an array of fences and waits for either any
		or all of them to be signaled before returning. The VK_TRUE we pass here
		indicates that we want to wait for all fences, but in the case of a single one
		it obviously doesn't matter. Just like vkAcquireNextImageKHR this function also
		takes a timeout. Unlike the semaphores, we manually need to restore the fence to
		the unsignaled state by resetting it with the vkResetFences call.

		Fences are created in the unsignaled state by default, which means that
		vkWaitForFences will wait forever if we haven't used the fence before. To solve that,
		we can change the fence creation to initialize it in the signaled state as if we had
		rendered an initial frame that finished in the createSyncObjects function:
		*/
		vkWaitForFences(device, 1, &inFlightFences[currentFrame], VK_TRUE, UINT64_MAX);

		/*
		The first two parameters of vkAcquireNextImageKHR are the logical device and the swap chain
		from which we wish to acquire an image. The third parameter specifies a timeout in
		nanoseconds for an image to become available. Using the maximum value of a 64 bit
		unsigned integer disables the timeout.

		The next two parameters specify synchronization objects that are to be signaled when the
		presentation engine is finished using the image. That's the point in time where we can
		start drawing to it. It is possible to specify a semaphore, fence or both. We're going
		to use our imageAvailableSemaphore for that purpose here.

		The last parameter specifies a variable to output the index of the swap chain image that
		has become available. The index refers to the VkImage in our swapChainImages array.
		We're going to use that index to pick the right command buffer.

		Vulkan will usually just tell us that the swap chain is no longer adequate during presentation.
		The vkAcquireNextImageKHR and vkQueuePresentKHR functions can return the following special
		values to indicate this.

		VK_ERROR_OUT_OF_DATE_KHR: The swap chain has become incompatible with the surface and can no
		longer be used for rendering. Usually happens after a window resize.

		VK_SUBOPTIMAL_KHR: The swap chain can still be used to successfully present to the surface,
		but the surface properties are no longer matched exactly.
		*/
		uint32_t imageIndex;
		VkResult result = vkAcquireNextImageKHR(device, swapChain, UINT64_MAX, imageAvailableSemaphores[currentFrame], VK_NULL_HANDLE, &imageIndex);

		if (result == VK_ERROR_OUT_OF_DATE_KHR)
		{
			recreateSwapChain();
			return;
		}
		else if (result != VK_SUCCESS && result != VK_SUBOPTIMAL_KHR)
		{
			throw std::runtime_error("failed to acquire swap chain image!");
		}

		// Check if a previous frame is using this image (i.e. there is its fence to wait on)
		if (imagesInFlight[imageIndex] != VK_NULL_HANDLE)
		{
			vkWaitForFences(device, 1, &imagesInFlight[imageIndex], VK_TRUE, UINT64_MAX);
		}
		// Mark the image as now being in use by this frame
		imagesInFlight[imageIndex] = inFlightFences[currentFrame];

		updateUniformBuffer(imageIndex);

		VkSubmitInfo submitInfo{};
		submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;

		/*
		The first three parameters specify which semaphores to wait on before execution begins
		and in which stage(s) of the pipeline to wait. We want to wait with writing colors to
		the image until it's available, so we're specifying the stage of the graphics pipeline
		that writes to the color attachment. That means that theoretically the implementation
		can already start executing our vertex shader and such while the image is not yet available.
		Each entry in the waitStages array corresponds to the semaphore with the same index in
		pWaitSemaphores.
		*/
		VkSemaphore waitSemaphores[] = { imageAvailableSemaphores[currentFrame] };
		VkPipelineStageFlags waitStages[] = { VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT };
		submitInfo.waitSemaphoreCount = 1;
		submitInfo.pWaitSemaphores = waitSemaphores;
		submitInfo.pWaitDstStageMask = waitStages;

		/*
		The next two parameters specify which command buffers to actually submit for execution.
		As mentioned earlier, we should submit the command buffer that binds the swap chain
		image we just acquired as color attachment.
		*/
		submitInfo.commandBufferCount = 1;
		submitInfo.pCommandBuffers = &commandBuffers[imageIndex];

		/*
		The signalSemaphoreCount and pSignalSemaphores parameters specify which semaphores to
		signal once the command buffer(s) have finished execution. In our case we're using
		the renderFinishedSemaphore for that purpose.
		*/
		VkSemaphore signalSemaphores[] = { renderFinishedSemaphores[currentFrame] };
		submitInfo.signalSemaphoreCount = 1;
		submitInfo.pSignalSemaphores = signalSemaphores;

		vkResetFences(device, 1, &inFlightFences[currentFrame]);

		/*
		We can now submit the command buffer to the graphics queue using vkQueueSubmit.
		The function takes an array of VkSubmitInfo structures as argument for efficiency
		when the workload is much larger.

		The vkQueueSubmit call includes an optional parameter to pass a fence that should be
		signaled when the command buffer finishes executing. We can use this to signal that
		a frame has finished.
		*/
		if (vkQueueSubmit(graphicsQueue, 1, &submitInfo, inFlightFences[currentFrame]) != VK_SUCCESS)
		{
			throw std::runtime_error("failed to submit draw command buffer!");
		}

		/*
		Subpass dependencies
		Remember that the subpasses in a render pass automatically take care of image
		layout transitions. These transitions are controlled by subpass dependencies,
		which specify memory and execution dependencies between subpasses. We have only
		a single subpass right now, but the operations right before and right after this
		subpass also count as implicit "subpasses".

		There are two built-in dependencies that take care of the transition at the start
		of the render pass and at the end of the render pass, but the former does not occur
		at the right time. It assumes that the transition occurs at the start of the pipeline,
		but we haven't acquired the image yet at that point! There are two ways to deal with
		this problem. We could change the waitStages for the imageAvailableSemaphore to
		VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT to ensure that the render passes don't begin
		until the image is available, or we can make the render pass wait for the
		VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT stage. I've decided to go with the second
		option here, because it's a good excuse to have a look at subpass dependencies and how they work.
		*/


		/*
		The last step of drawing a frame is submitting the result back to the swap chain to have it
		eventually show up on the screen. Presentation is configured through a VkPresentInfoKHR
		structure at the end of the drawFrame function.
		*/
		VkPresentInfoKHR presentInfo{};
		presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR;

		/*
		The first two parameters specify which semaphores to wait on before presentation can happen,
		just like VkSubmitInfo.
		*/
		presentInfo.waitSemaphoreCount = 1;
		presentInfo.pWaitSemaphores = signalSemaphores;

		/*
		The next two parameters specify the swap chains to present images to and the index of the image
		for each swap chain. This will almost always be a single one.
		*/
		VkSwapchainKHR swapChains[] = { swapChain };
		presentInfo.swapchainCount = 1;
		presentInfo.pSwapchains = swapChains;
		presentInfo.pImageIndices = &imageIndex;
		/*
		There is one last optional parameter called pResults. It allows you to specify an array of
		VkResult values to check for every individual swap chain if presentation was successful.
		It's not necessary if you're only using a single swap chain, because you can simply use
		the return value of the present function.
		*/
		presentInfo.pResults = nullptr; // Optional

		/*
		If you run your application with validation layers enabled now you may either get errors
		or notice that the memory usage slowly grows. The reason for this is that the application
		is rapidly submitting work in the drawFrame function, but doesn't actually check if any of
		it finishes. If the CPU is submitting work faster than the GPU can keep up with then the
		queue will slowly fill up with work. Worse, even, is that we are reusing the
		imageAvailableSemaphore and renderFinishedSemaphore semaphores, along with the command buffers,
		for multiple frames at the same time!

		The easy way to solve this is to wait for work to finish right after submitting it, for example
		by using vkQueueWaitIdle:

		But that is not optimal, so we will try to use vector of fences and semaphore to submit multiple
		frames as we can.

		So vkQueueWaitIdle(presentQueue) is disabled
		*/
		//vkQueueWaitIdle(presentQueue);

		/*
		However, we are likely not optimally using the GPU in this way, because the whole graphics
		pipeline is only used for one frame at a time right now. The stages that the current frame
		has already progressed through are idle and could already be used for a next frame.
		We will now extend our application to allow for multiple frames to be in-flight while still
		bounding the amount of work that piles up.

		Start by adding a constant at the top of the program that defines how many frames should be
		processed concurrently:

		for example: const int MAX_FRAMES_IN_FLIGHT = 2;

		By using the modulo (%) operator, we ensure that the frame index loops around after every
		MAX_FRAMES_IN_FLIGHT enqueued frames.

		Although we've now set up the required objects to facilitate processing of multiple frames
		simultaneously, we still don't actually prevent more than MAX_FRAMES_IN_FLIGHT from being
		submitted. Right now there is only GPU-GPU synchronization and no CPU-GPU synchronization
		going on to keep track of how the work is going. We may be using the frame #0 objects while
		frame #0 is still in-flight!

		To perform CPU-GPU synchronization, Vulkan offers a second type of synchronization primitive
		called fences. Fences are similar to semaphores in the sense that they can be signaled and
		waited for, but this time we actually wait for them in our own code. We'll first create a
		fence for each frame:
		*/
		result = vkQueuePresentKHR(presentQueue, &presentInfo);

		/*
		It is important to do this after vkQueuePresentKHR to ensure that the semaphores are in a
		consistent state, otherwise a signalled semaphore may never be properly waited upon.
		*/
		if (result == VK_ERROR_OUT_OF_DATE_KHR || result == VK_SUBOPTIMAL_KHR || framebufferResized)
		{
			framebufferResized = false;
			recreateSwapChain();
		}
		else if (result != VK_SUCCESS)
		{
			throw std::runtime_error("failed to present swap chain image!");
		}

		currentFrame = (currentFrame + 1) % MAX_FRAMES_IN_FLIGHT;
	}

	void updateUniformBuffer(uint32_t currentImage)
	{
		/*
		The updateUniformBuffer function will start out with some logic to calculate the time in
		seconds since rendering has started with floating point accuracy.
		*/
		static auto startTime = std::chrono::high_resolution_clock::now();

		auto currentTime = std::chrono::high_resolution_clock::now();
		float time = std::chrono::duration<float, std::chrono::seconds::period>(currentTime - startTime).count();

		/*
		The glm::rotate function takes an existing transformation, rotation angle and rotation
		axis as parameters. The glm::mat4(1.0f) constructor returns an identity matrix.
		Using a rotation angle of time * glm::radians(90.0f) accomplishes the purpose of rotation
		90 degrees per second.
		*/
		UniformBufferObject ubo{};
		ubo.model = glm::rotate(glm::mat4(1.0f), time * glm::radians(90.0f), glm::vec3(0.0f, 0.0f, 1.0f));

		/*
		For the view transformation I've decided to look at the geometry from above at a 45 degree angle.
		The glm::lookAt function takes the eye position, center position and up axis as parameters.
		*/
		//ubo.view = glm::lookAt(glm::lerp() abs(glm::sin(time / 2)) * glm::vec3(9.0f, 9.0f, 9.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 0.0f, 1.0f));
		ubo.view = glm::lookAt(glm::vec3(2.0f, 2.0f, 2.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 0.0f, 1.0f));

		/*
		I've chosen to use a perspective projection with a 45 degree vertical field-of-view.
		The other parameters are the aspect ratio, near and far view planes. It is important
		to use the current swap chain extent to calculate the aspect ratio to take into account
		the new width and height of the window after a resize.
		*/
		ubo.proj = glm::perspective(glm::radians(45.0f), swapChainExtent.width / (float)swapChainExtent.height, 0.1f, 10.0f);

		/*
		GLM was originally designed for OpenGL, where the Y coordinate of the clip coordinates is inverted.
		The easiest way to compensate for that is to flip the sign on the scaling factor of the Y axis in
		the projection matrix. If you don't do this, then the image will be rendered upside down
		*/
		ubo.proj[1][1] *= -1;

		/*
		All of the transformations are defined now, so we can copy the data in the uniform buffer
		object to the current uniform buffer. This happens in exactly the same way as we did for
		vertex buffers, except without a staging buffer:

		Using a UBO this way is not the most efficient way to pass frequently changing values to
		the shader. A more efficient way to pass a small buffer of data to shaders are push constants.
		*/
		void* data;
		vkMapMemory(device, uniformBuffersMemory[currentImage], 0, sizeof(ubo), 0, &data);
		memcpy(data, &ubo, sizeof(ubo));
		vkUnmapMemory(device, uniformBuffersMemory[currentImage]);
	}

	void cleanup()
	{
		cleanupSwapChain();

		vkDestroySampler(device, textureSampler, nullptr);
		vkDestroyImageView(device, textureImageView, nullptr);

		vkDestroyImage(device, textureImage, nullptr);
		vkFreeMemory(device, textureImageMemory, nullptr);

		vkDestroyDescriptorSetLayout(device, descriptorSetLayout, nullptr);

		vkDestroyBuffer(device, indexBuffer, nullptr);
		vkFreeMemory(device, indexBufferMemory, nullptr);

		vkDestroyBuffer(device, vertexBuffer, nullptr);
		vkFreeMemory(device, vertexBufferMemory, nullptr);

		for (size_t i = 0; i < MAX_FRAMES_IN_FLIGHT; i++)
		{
			vkDestroySemaphore(device, renderFinishedSemaphores[i], nullptr);
			vkDestroySemaphore(device, imageAvailableSemaphores[i], nullptr);
			vkDestroyFence(device, inFlightFences[i], nullptr);
		}

		vkDestroyCommandPool(device, commandPool, nullptr);

		vkDestroyDevice(device, nullptr);
		if (enableValidationLayers)
		{
			DestroyDebugUtilsMessengerEXT(instance, debugMessenger, nullptr);
		}

		//GLFW doesn't offer a special function for destroying a surface,
		//but that can easily be done through the original API
		vkDestroySurfaceKHR(instance, surface, nullptr);
		vkDestroyInstance(instance, nullptr);
		glfwDestroyWindow(window);
		glfwTerminate();
	}

};

int main()
{
	HelloTriangleApplication app;
	try
	{
		app.run();
	}
	catch (const std::exception& e)
	{
		std::cerr << e.what() << std::endl;
		return EXIT_FAILURE;
	}
	//system("PAUSE");
	return EXIT_SUCCESS;
}
